## Blessing or curse? A survey on the Impact of Generative AI on Fake News
https://arxiv.org/abs/2404.03021

### Summary

Survey ie a collection of other people works

### Content

The development of information dissemination has a long history of influencing public perception and political land- scapes **Cambridge Analytica**, a British political consulting firm, became widely known for its role in the 2016 United States presidential election and the Brexit referendum [https://ieeexplore.ieee.org/document/8364652] The company specialized in data mining, data analysis, and strategic communication during electoral processes. The Cambridge Analytica scandal used data ana- lytics in influencing voter behavior through targeted, at the time, hand crafted political advertising on social media

the term **“Generative Artificial Intelligence (AI)”** refers to AI technologies designed to produce new and original content. This content includes text, images, audio, and other media forms, often matching the sophistication and authenticity of human-generated output. Models like GPT-4, with their human-like text generation, are able to pass the Turing test [https://www.nature.com/articles/d41586-023-02361-7]

The synthesis of **recent advancements in Generative AI** and its application to the generation and detection of Fake News reveals a rapidly evolving field marked by interdisci- plinary contributions. From the foundational work by Devlin et al. (2018) on BERT, which revolutionized natural language processing (NLP) through deep bidirectional transformers, to the innovative detection models like exBAKE by Jwa et al. (2019) and the application of transformers in identifying automatically generated headlines by Maronikolakis et al. (2021), the landscape of Fake News detection has significantly expanded [https://arxiv.org/abs/1810.04805 ; https://arxiv.org/abs/2009.13375 ; https://www.mdpi.com/2076-3417/9/19/4062]

The role of **AI in both facilitating and combating the spread of Fake News** introduces a paradox that researchers must navigate. While generative AI models have the potential to create highly realistic and misleading content, as explored by Mosallanezhad et al. (2020) and Cocchi et al. (2023), they also offer the tools necessary for the development of sophisticated detection algorithms [https://arxiv.org/abs/2010.16324 ; https://iris.unimore.it/retrieve/5e39d149-d12a-480e-8014-c9d734d065a8/2023-iciap-deepfake.pdf]

![Structural overview of the domain of Generative AI and its impact on Fake News, illustrating the main themes of creation and detection, along with their subtopics and interrelations. Blue indicates the main themes of the domain; green highlights the subtopics related to these main themes; and yellow denotes key technologies and methodologies central to understanding and addressing the challenges in this domain.](imgs/GAI_2404.png)

GPT: Generative Pre-trained Transformer **(GPT) models** represent a significant advancement in language pro- cessing, capable of generating coherent and contextually rel- evant text based on a given prompt, which is a user-defined input that guides the model’s text generation process. These models are distinguished by their ability to perform a wide array of language tasks without task-specific training [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf]

**Fake news detection** [https://link.springer.com/chapter/10.1007/978-3-030-68787-8_45]

Maronikolakis et al. (2021) tackle the challenge of **iden- tifying automatically generated headlines**, demonstrating that transformers significantly outperform humans in distinguish- ing real from Fake News content [https://arxiv.org/abs/2009.13375]

Vijjali et al. (2020) develop a two-stage **transformer-based model for detecting COVID-19 related Fake News**, combining fact-checking with textual entailment to verify claims, show- casing the adaptability of transformer models to current events and specific domains [https://arxiv.org/abs/2011.13253]

Bubeck et al. (2023) examine **GPT-4**, highlighting its near- human capabilities across multiple disciplines, indicating a move towards **artificial general intelligence (AGI)** [https://arxiv.org/abs/2303.12712]. GPT-4 emerges as a frontrunner among a new generation of LLMs, including ChatGPT and Google’s PaLM, demonstrating capa- bilities that closely mirror human intelligence across diverse fields such as mathematics, coding, vision, medicine, law, and psychology. GPT-4’s performance, superior to predecessors, showcases its versatility in solving novel tasks without specific prompts. This study positions GPT-4 as an early form of AGI, emphasizing its societal implications and the necessity for a new research paradigm beyond next-word prediction

Public perceptions of **deepfake technology** can significantly influence its impact on society. For instance, [https://dl.acm.org/doi/abs/10.1002/pra2.1035] has illus- trated that even a single deceptive video could instigate severe geopolitical tensions, highlighting the urgent need for robust verification measures

**deepfake detection with CNN and DCGANS:** https://ieeexplore.ieee.org/document/10263628

**produce hyper-realistic Fake News** content in text, image, audio, and video formats [https://link.springer.com/article/10.1007/s42001-024-00250-1]

## Advancing Hate Speech Detection with Transformers: Insights from the MetaHate
https://www.arxiv.org/abs/2508.04913?utm_source=chatgpt.com

### Summary

evaluate hate-speech recognition of different LLMs on MetaHate dataset 

### Content

large-scale investigation into the contextual detection of hate speech using LLMs, using the extensive MetaHate [https://arxiv.org/html/2401.06526v1] dataset, by evaluating  BART, ELECTRA, BERT, RoBERTa, and GPT-2 using the Meta- Hate dataset. Among the evaluated models, ELECTRA achieved the highest F1 score, outperforming all other baselines in hate speech classification. a small but significant proportion of MetaHate samples may be mislabeled e advocate for semi-automated relabeling tools using explainable AI

### Citations 

The rise of social networks and online platforms has increased global connectivity but also highlighted a trou- bling surge in hate speech across geographical and cultural boundaries. In recent studies, approximately 30% of the adolescents surveyed reported experiencing cyberbullying at some point in their lives. Furthermore, around 13% indicated that they had been cyberbullied within the 30 days before the survey [https://cyberbullying.org/facts]

addressing hate speech remains challenging due to complex and varying contexts, coded language, indirect expressions, and evolving slang; Advances in artificial intelligence (AI) and machine learning (ML) have shown promise in this area [https://arxiv.org/abs/1804.04257]
