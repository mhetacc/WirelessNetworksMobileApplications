\section{Introduction}

Artificial intelligence has fascinated the scientific community for almost a century, spurring famous research papers such as Alan Turing's \textit{"Computing Machinery and Intelligence"} in 1950 \cite{turing_computing_1950}, which introduced the \textit{imitation game}. The idea, trivialized, is that any machine capable of fooling a person into thinking it's speaking to a human can be considered sentient. For seventy-three years the game remained unbeaten, until OpenAI's ChatGPT-4 ultimately succeeded in 2023 \cite{biever_chatgpt_2023}. The model, simulating AGI capabilities \cite{bubeck_sparks_2023}, is one of the last iterations of the Generative Pre-Training LLMs\footnote{Large Language Models (LLMs) are trained with supervised machine learning on vast amount of textual data, and are designed for natural language processing tasks, especially language generation \cite{brown_language_2020,bommasani_opportunities_2022}} pioneered by OpenAI in 2018 (at the moment of writing the latest available is GPT-5.2) \cite{radford_improving_2018}, which closely followed the first breakthrough towards human-like agents: \textit{"Attention Is All You Need"} \cite{vaswani_attention_2023} is a 2017 landmark research paper authored by eight Google researchers that introduced the \textit{transformer} architecture, considered the backbone of all modern LLMs and the main contributor of the AI boom \cite{miller_artificial_2023}.

Computer scientists are not the only ones engrossed in the topic: philosophers involved themselves too, most notably Jhon Searle and his 1980s' \textit{chinese room} thought experiment, which directly challenged Turing's ideas and refuted the possibility of true machine intelligence \cite{searle_minds_1980}, and even the general public showed great interest once AIs became smart enough: ChatGPT reached one million users in just five days \cite{mollman_artificial_2022}, an astonishing feat when compared to other technologies such as personal computers, which needed almost ten years to reach the same milestone \cite{reimer_total_2005}.

Despite all of the above, the field of artificial intelligence comes with its fair share of problems and controversies: due to their inherent design, LLMs pose significant privacy risks as sensitive information is collected and used to create and fine-tune the models themselves \cite{gomstyn_exploring_2024}, and their black-box nature makes it difficult to understand and predict their behavior \cite{von_eschenbach_transparency_2021}. Moreover, they are often trained on pirated material, like books \cite{reisner_unbelievable_2025} or art \cite{milmo_mass_2025}, igniting protests in many creative communities, such as hollywood writers \cite{morris_ai_2025} or video game actors \cite{press_over_2024}. It follows that artificial intelligence technologies should be handled carefully, without hindering their development while limiting the damages they can cause to society and individuals. 

This survey paper aims to present the current state of research on ethical and human-centric artificial intelligence, exploring how models and humans can influence each other and their environment. Section \ref{sec:ai_fkns} showcases generation and detection of fake-news, section \ref{sec:ai_humancentric} recognition and simulation of human behaviour, as well as how to influence it. Section \ref{sec:ai_biases} concerns itself with biases and tendencies of the models themselves, and lastly section \ref{sec:ai_ethical} explores ways to develop ethical LLMs that can positively impact individuals and society.