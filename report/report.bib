
@article{berghel_malice_2018,
	title = {Malice Domestic: The Cambridge Analytica Dystopia},
	volume = {51},
	issn = {1558-0814},
	url = {https://ieeexplore.ieee.org/document/8364652},
	doi = {10.1109/MC.2018.2381135},
	shorttitle = {Malice Domestic},
	abstract = {Partisan consultancies like Cambridge Analytica that use data analytics to sway the electorate rely on social network users’ participation in their own psychological manipulation.},
	pages = {84--89},
	number = {5},
	journaltitle = {Computer},
	author = {Berghel, Hal},
	urldate = {2026-01-08},
	date = {2018-05},
	keywords = {Cambridge Analytica, electoral manipulation, Facebook, history of computing, Out of Band, privacy, social media},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/JRFPSW9C/Berghel - 2018 - Malice Domestic The Cambridge Analytica Dystopia.pdf:application/pdf},
}

@online{reimer_total_2005,
	title = {Total share: 30 years of personal computer market share figures},
	url = {https://arstechnica.com/features/2005/12/total-share/},
	shorttitle = {Total share},
	abstract = {It's been a long, strange trip for the personal computer over 30 years. Ars …},
	titleaddon = {Ars Technica},
	author = {Reimer, Jeremy},
	urldate = {2026-01-09},
	date = {2005-12-15},
	langid = {english},
	file = {Snapshot:/home/mhetac/Zotero/storage/NW2IFB4U/total-share.html:text/html},
}


@article{searle_minds_1980,
	title = {Minds, brains, and programs},
	volume = {3},
	issn = {1469-1825, 0140-525X},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/minds-brains-and-programs/DC644B47A4299C637C89772FACC2706A},
	doi = {10.1017/S0140525X00005756},
	abstract = {This article can be viewed as an attempt to explore the consequences of two propositions. (1) Intentionality in human beings (and animals) is a product of causal features of the brain. I assume this is an empirical fact about the actual causal relations between mental processes and brains. It says simply that certain brain processes are sufficient for intentionality. (2) Instantiating a computer program is never by itself a sufficient condition of intentionality. The main argument of this paper is directed at establishing this claim. The form of the argument is to show how a human agent could instantiate the program and still not have the relevant intentionality. These two propositions have the following consequences: (3) The explanation of how the brain produces intentionality cannot be that it does it by instantiating a computer program. This is a strict logical consequence of 1 and 2. (4) Any mechanism capable of producing intentionality must have causal powers equal to those of the brain. This is meant to be a trivial consequence of 1. (5) Any attempt literally to create intentionality artificially (strong {AI}) could not succeed just by designing programs but would have to duplicate the causal powers of the human brain. This follows from 2 and 4.“Could a machine think?” On the argument advanced here only a machine could think, and only very special kinds of machines, namely brains and machines with internal causal powers equivalent to those of brains. And that is why strong {AI} has little to tell us about thinking, since it is not about machines but about programs, and no program by itself is sufficient for thinking.},
	pages = {417--424},
	number = {3},
	journaltitle = {Behavioral and Brain Sciences},
	author = {Searle, John R.},
	urldate = {2026-01-09},
	date = {1980-09},
	langid = {english},
	keywords = {artificial intelligence, brain, intentionality, mind},
}

@online{miller_artificial_2023,
	title = {The Artificial Intelligence Boom},
	url = {https://engineering.washu.edu/news/magazine/2023-fall/the-artificial-intelligence-boom.html},
	abstract = {The rapid rollout of new forms of artificial intelligence has led to widespread adoption, but also a lot of questions: Is this a benefit or a cause for concern?},
	author = {Miller, Beth},
	urldate = {2026-01-08},
	date = {2023},
	langid = {english},
	file = {Snapshot:/home/mhetac/Zotero/storage/KQL7RLKA/the-artificial-intelligence-boom.html:text/html},
}

@misc{vaswani_attention_2017,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@article{biever_chatgpt_2023,
	title = {{ChatGPT} broke the Turing test — the race is on for new ways to assess {AI}},
	volume = {619},
	rights = {2023 Springer Nature Limited},
	url = {https://www.nature.com/articles/d41586-023-02361-7},
	doi = {10.1038/d41586-023-02361-7},
	abstract = {Large language models mimic human chatter, but scientists disagree on their ability to reason.},
	pages = {686--689},
	number = {7971},
  year = {2023},
	journaltitle = {Nature},
	author = {Biever, Celeste},
	urldate = {2026-01-08},
	date = {2023-07-25},
	langid = {english},
	note = {Bandiera\_abtest: a
Cg\_type: News Feature
Publisher: Nature Publishing Group
Subject\_term: Computer science, Mathematics and computing, Technology, Society},
	keywords = {Computer science, Mathematics and computing, Society, Technology},
	file = {Snapshot:/home/mhetac/Zotero/storage/UEPVMUYE/d41586-023-02361-7.html:text/html},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of Artificial General Intelligence: Early experiments with {GPT}-4},
	url = {http://arxiv.org/abs/2303.12712},
	doi = {10.48550/arXiv.2303.12712},
	shorttitle = {Sparks of Artificial General Intelligence},
	abstract = {Artificial intelligence ({AI}) researchers have been developing and refining large language models ({LLMs}) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by {OpenAI}, {GPT}-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of {GPT}-4, when it was still in active development by {OpenAI}. We contend that (this early version of) {GPT}-4 is part of a new cohort of {LLMs} (along with {ChatGPT} and Google's {PaLM} for example) that exhibit more general intelligence than previous {AI} models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, {GPT}-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, {GPT}-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as {ChatGPT}. Given the breadth and depth of {GPT}-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence ({AGI}) system. In our exploration of {GPT}-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of {AGI}, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
	number = {{arXiv}:2303.12712},
	publisher = {{arXiv}},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	urldate = {2026-01-08},
	date = {2023-04-13},
	eprinttype = {arxiv},
	eprint = {2303.12712 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/UYHN97FC/Bubeck et al. - 2023 - Sparks of Artificial General Intelligence Early experiments with GPT-4.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/VEGAW73Y/2303.html:text/html},
}

@article{patil_transformative_2024,
	title = {Transformative Trends in Generative {AI}: Harnessing Large Language Models for Natural Language Understanding and Generation},
	volume = {12},
	rights = {Copyright (c) 2023},
	issn = {2147-6799},
	url = {https://ijisae.org/index.php/IJISAE/article/view/3794},
	shorttitle = {Transformative Trends in Generative {AI}},
	abstract = {The advent of Large Language Models ({LLMs}) has ushered in transformative trends in the field of Generative Artificial Intelligence ({AI}). These models, with billions of parameters, have demonstrated unparalleled capabilities in Natural Language Understanding ({NLU}) and Generation ({NLG}) tasks. This paper delves into the evolution of generative {AI}, emphasizing the pivotal role played by {LLMs}. We explore the mechanisms by which these models have revolutionized {NLU} and {NLG} through their capacity to process vast amounts of textual data and generate coherent and contextually relevant text. Additionally, we investigate the techniques and methodologies employed in harnessing the power of {LLMs} for various applications, ranging from chatbots and content generation to machine translation and sentiment analysis. Furthermore, we examine the challenges associated with {LLM}-based generative {AI}, such as ethical concerns, model bias, and the computational resources required for training and fine-tuning. Finally, we offer insights into the future directions of research in this domain, with a focus on optimizing {LLMs} for broader applications, mitigating their limitations, and ensuring their responsible deployment in real-world scenarios. This paper serves as a comprehensive overview of the current state of generative {AI}, shedding light on its potential to reshape the way we interact with and generate natural language content.},
	pages = {309--319},
	number = {4},
	journaltitle = {International Journal of Intelligent Systems and Applications in Engineering},
	author = {Patil, Dinesh D. and Dhotre, Dhanraj R. and Gawande, Gopal S. and Mate, Dipali S. and Shelke, Mayura V. and Bhoye, Tejaswini S.},
	urldate = {2026-01-08},
	date = {2024},
	langid = {english},
	keywords = {Data Privacy},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/UN2EFWB2/Patil et al. - 2024 - Transformative Trends in Generative AI Harnessing Large Language Models for Natural Language Unders.pdf:application/pdf},
}

@misc{openai_gpt-4_2024,
	title = {{GPT}-4 Technical Report},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of {GPT}-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, {GPT}-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. {GPT}-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of {GPT}-4's performance based on models trained with no more than 1/1,000th the compute of {GPT}-4.},
	number = {{arXiv}:2303.08774},
	publisher = {{arXiv}},
	author = {{OpenAI} and Achiam, Josh and Adler, Steven and Sandhini, Agarwal and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and Bernadett-Shapiro, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Simón Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and Gontijo-Lopes, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, Łukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, Łukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and {McGrew}, Bob and {McKinney}, Scott Mayer and {McLeavey}, Christine and {McMillan}, Paul and {McNeil}, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and Mély, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cerón and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
	urldate = {2026-01-08},
	date = {2024-03-04},
	eprinttype = {arxiv},
	eprint = {2303.08774 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/928YGCMA/OpenAI et al. - 2024 - GPT-4 Technical Report.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/2VZV34CJ/2303.html:text/html},
}

@misc{team_gemini_2025,
	title = {Gemini: A Family of Highly Capable Multimodal Models},
	url = {http://arxiv.org/abs/2312.11805},
	doi = {10.48550/arXiv.2312.11805},
	shorttitle = {Gemini},
	abstract = {This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark {MMLU}, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google {AI} Studio, and Cloud Vertex {AI}.},
	number = {{arXiv}:2312.11805},
	publisher = {{arXiv}},
	author = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M. and Hauth, Anja and Millican, Katie and Silver, David and Johnson, Melvin and Antonoglou, Ioannis and Schrittwieser, Julian and Glaese, Amelia and Chen, Jilin and Pitler, Emily and Lillicrap, Timothy and Lazaridou, Angeliki and Firat, Orhan and Molloy, James and Isard, Michael and Barham, Paul R. and Hennigan, Tom and Lee, Benjamin and Viola, Fabio and Reynolds, Malcolm and Xu, Yuanzhong and Doherty, Ryan and Collins, Eli and Meyer, Clemens and Rutherford, Eliza and Moreira, Erica and Ayoub, Kareem and Goel, Megha and Krawczyk, Jack and Du, Cosmo and Chi, Ed and Cheng, Heng-Tze and Ni, Eric and Shah, Purvi and Kane, Patrick and Chan, Betty and Faruqui, Manaal and Severyn, Aliaksei and Lin, Hanzhao and Li, {YaGuang} and Cheng, Yong and Ittycheriah, Abe and Mahdieh, Mahdis and Chen, Mia and Sun, Pei and Tran, Dustin and Bagri, Sumit and Lakshminarayanan, Balaji and Liu, Jeremiah and Orban, Andras and Güra, Fabian and Zhou, Hao and Song, Xinying and Boffy, Aurelien and Ganapathy, Harish and Zheng, Steven and Choe, {HyunJeong} and Weisz, Ágoston and Zhu, Tao and Lu, Yifeng and Gopal, Siddharth and Kahn, Jarrod and Kula, Maciej and Pitman, Jeff and Shah, Rushin and Taropa, Emanuel and Merey, Majd Al and Baeuml, Martin and Chen, Zhifeng and Shafey, Laurent El and Zhang, Yujing and Sercinoglu, Olcan and Tucker, George and Piqueras, Enrique and Krikun, Maxim and Barr, Iain and Savinov, Nikolay and Danihelka, Ivo and Roelofs, Becca and White, Anaïs and Andreassen, Anders and Glehn, Tamara von and Yagati, Lakshman and Kazemi, Mehran and Gonzalez, Lucas and Khalman, Misha and Sygnowski, Jakub and Frechette, Alexandre and Smith, Charlotte and Culp, Laura and Proleev, Lev and Luan, Yi and Chen, Xi and Lottes, James and Schucher, Nathan and Lebron, Federico and Rrustemi, Alban and Clay, Natalie and Crone, Phil and Kocisky, Tomas and Zhao, Jeffrey and Perz, Bartek and Yu, Dian and Howard, Heidi and Bloniarz, Adam and Rae, Jack W. and Lu, Han and Sifre, Laurent and Maggioni, Marcello and Alcober, Fred and Garrette, Dan and Barnes, Megan and Thakoor, Shantanu and Austin, Jacob and Barth-Maron, Gabriel and Wong, William and Joshi, Rishabh and Chaabouni, Rahma and Fatiha, Deeni and Ahuja, Arun and Tomar, Gaurav Singh and Senter, Evan and Chadwick, Martin and Kornakov, Ilya and Attaluri, Nithya and Iturrate, Iñaki and Liu, Ruibo and Li, Yunxuan and Cogan, Sarah and Chen, Jeremy and Jia, Chao and Gu, Chenjie and Zhang, Qiao and Grimstad, Jordan and Hartman, Ale Jakse and Garcia, Xavier and Pillai, Thanumalayan Sankaranarayana and Devlin, Jacob and Laskin, Michael and Casas, Diego de Las and Valter, Dasha and Tao, Connie and Blanco, Lorenzo and Badia, Adrià Puigdomènech and Reitter, David and Chen, Mianna and Brennan, Jenny and Rivera, Clara and Brin, Sergey and Iqbal, Shariq and Surita, Gabriela and Labanowski, Jane and Rao, Abhi and Winkler, Stephanie and Parisotto, Emilio and Gu, Yiming and Olszewska, Kate and Addanki, Ravi and Miech, Antoine and Louis, Annie and Teplyashin, Denis and Brown, Geoff and Catt, Elliot and Balaguer, Jan and Xiang, Jackie and Wang, Pidong and Ashwood, Zoe and Briukhov, Anton and Webson, Albert and Ganapathy, Sanjay and Sanghavi, Smit and Kannan, Ajay and Chang, Ming-Wei and Stjerngren, Axel and Djolonga, Josip and Sun, Yuting and Bapna, Ankur and Aitchison, Matthew and Pejman, Pedram and Michalewski, Henryk and Yu, Tianhe and Wang, Cindy and Love, Juliette and Ahn, Junwhan and Bloxwich, Dawn and Han, Kehang and Humphreys, Peter and Sellam, Thibault and Bradbury, James and Godbole, Varun and Samangooei, Sina and Damoc, Bogdan and Kaskasoli, Alex and Arnold, Sébastien M. R. and Vasudevan, Vijay and Agrawal, Shubham and Riesa, Jason and Lepikhin, Dmitry and Tanburn, Richard and Srinivasan, Srivatsan and Lim, Hyeontaek and Hodkinson, Sarah and Shyam, Pranav and Ferret, Johan and Hand, Steven and Garg, Ankush and Paine, Tom Le and Li, Jian and Li, Yujia and Giang, Minh and Neitz, Alexander and Abbas, Zaheer and York, Sarah and Reid, Machel and Cole, Elizabeth and Chowdhery, Aakanksha and Das, Dipanjan and Rogozińska, Dominika and Nikolaev, Vitaliy and Sprechmann, Pablo and Nado, Zachary and Zilka, Lukas and Prost, Flavien and He, Luheng and Monteiro, Marianne and Mishra, Gaurav and Welty, Chris and Newlan, Josh and Jia, Dawei and Allamanis, Miltiadis and Hu, Clara Huiyi and Liedekerke, Raoul de and Gilmer, Justin and Saroufim, Carl and Rijhwani, Shruti and Hou, Shaobo and Shrivastava, Disha and Baddepudi, Anirudh and Goldin, Alex and Ozturel, Adnan and Cassirer, Albin and Xu, Yunhan and Sohn, Daniel and Sachan, Devendra and Amplayo, Reinald Kim and Swanson, Craig and Petrova, Dessie and Narayan, Shashi and Guez, Arthur and Brahma, Siddhartha and Landon, Jessica and Patel, Miteyan and Zhao, Ruizhe and Villela, Kevin and Wang, Luyu and Jia, Wenhao and Rahtz, Matthew and Giménez, Mai and Yeung, Legg and Keeling, James and Georgiev, Petko and Mincu, Diana and Wu, Boxi and Haykal, Salem and Saputro, Rachel and Vodrahalli, Kiran and Qin, James and Cankara, Zeynep and Sharma, Abhanshu and Fernando, Nick and Hawkins, Will and Neyshabur, Behnam and Kim, Solomon and Hutter, Adrian and Agrawal, Priyanka and Castro-Ros, Alex and Driessche, George van den and Wang, Tao and Yang, Fan and Chang, Shuo-yiin and Komarek, Paul and {McIlroy}, Ross and Lučić, Mario and Zhang, Guodong and Farhan, Wael and Sharman, Michael and Natsev, Paul and Michel, Paul and Bansal, Yamini and Qiao, Siyuan and Cao, Kris and Shakeri, Siamak and Butterfield, Christina and Chung, Justin and Rubenstein, Paul Kishan and Agrawal, Shivani and Mensch, Arthur and Soparkar, Kedar and Lenc, Karel and Chung, Timothy and Pope, Aedan and Maggiore, Loren and Kay, Jackie and Jhakra, Priya and Wang, Shibo and Maynez, Joshua and Phuong, Mary and Tobin, Taylor and Tacchetti, Andrea and Trebacz, Maja and Robinson, Kevin and Katariya, Yash and Riedel, Sebastian and Bailey, Paige and Xiao, Kefan and Ghelani, Nimesh and Aroyo, Lora and Slone, Ambrose and Houlsby, Neil and Xiong, Xuehan and Yang, Zhen and Gribovskaya, Elena and Adler, Jonas and Wirth, Mateo and Lee, Lisa and Li, Music and Kagohara, Thais and Pavagadhi, Jay and Bridgers, Sophie and Bortsova, Anna and Ghemawat, Sanjay and Ahmed, Zafarali and Liu, Tianqi and Powell, Richard and Bolina, Vijay and Iinuma, Mariko and Zablotskaia, Polina and Besley, James and Chung, Da-Woon and Dozat, Timothy and Comanescu, Ramona and Si, Xiance and Greer, Jeremy and Su, Guolong and Polacek, Martin and Kaufman, Raphaël Lopez and Tokumine, Simon and Hu, Hexiang and Buchatskaya, Elena and Miao, Yingjie and Elhawaty, Mohamed and Siddhant, Aditya and Tomasev, Nenad and Xing, Jinwei and Greer, Christina and Miller, Helen and Ashraf, Shereen and Roy, Aurko and Zhang, Zizhao and Ma, Ada and Filos, Angelos and Besta, Milos and Blevins, Rory and Klimenko, Ted and Yeh, Chih-Kuan and Changpinyo, Soravit and Mu, Jiaqi and Chang, Oscar and Pajarskas, Mantas and Muir, Carrie and Cohen, Vered and Lan, Charline Le and Haridasan, Krishna and Marathe, Amit and Hansen, Steven and Douglas, Sholto and Samuel, Rajkumar and Wang, Mingqiu and Austin, Sophia and Lan, Chang and Jiang, Jiepu and Chiu, Justin and Lorenzo, Jaime Alonso and Sjösund, Lars Lowe and Cevey, Sébastien and Gleicher, Zach and Avrahami, Thi and Boral, Anudhyan and Srinivasan, Hansa and Selo, Vittorio and May, Rhys and Aisopos, Konstantinos and Hussenot, Léonard and Soares, Livio Baldini and Baumli, Kate and Chang, Michael B. and Recasens, Adrià and Caine, Ben and Pritzel, Alexander and Pavetic, Filip and Pardo, Fabio and Gergely, Anita and Frye, Justin and Ramasesh, Vinay and Horgan, Dan and Badola, Kartikeya and Kassner, Nora and Roy, Subhrajit and Dyer, Ethan and Campos, Víctor Campos and Tomala, Alex and Tang, Yunhao and Badawy, Dalia El and White, Elspeth and Mustafa, Basil and Lang, Oran and Jindal, Abhishek and Vikram, Sharad and Gong, Zhitao and Caelles, Sergi and Hemsley, Ross and Thornton, Gregory and Feng, Fangxiaoyu and Stokowiec, Wojciech and Zheng, Ce and Thacker, Phoebe and Ünlü, Çağlar and Zhang, Zhishuai and Saleh, Mohammad and Svensson, James and Bileschi, Max and Patil, Piyush and Anand, Ankesh and Ring, Roman and Tsihlas, Katerina and Vezer, Arpi and Selvi, Marco and Shevlane, Toby and Rodriguez, Mikel and Kwiatkowski, Tom and Daruki, Samira and Rong, Keran and Dafoe, Allan and {FitzGerald}, Nicholas and Gu-Lemberg, Keren and Khan, Mina and Hendricks, Lisa Anne and Pellat, Marie and Feinberg, Vladimir and Cobon-Kerr, James and Sainath, Tara and Rauh, Maribeth and Hashemi, Sayed Hadi and Ives, Richard and Hasson, Yana and Noland, Eric and Cao, Yuan and Byrd, Nathan and Hou, Le and Wang, Qingze and Sottiaux, Thibault and Paganini, Michela and Lespiau, Jean-Baptiste and Moufarek, Alexandre and Hassan, Samer and Shivakumar, Kaushik and Amersfoort, Joost van and Mandhane, Amol and Joshi, Pratik and Goyal, Anirudh and Tung, Matthew and Brock, Andrew and Sheahan, Hannah and Misra, Vedant and Li, Cheng and Rakićević, Nemanja and Dehghani, Mostafa and Liu, Fangyu and Mittal, Sid and Oh, Junhyuk and Noury, Seb and Sezener, Eren and Huot, Fantine and Lamm, Matthew and Cao, Nicola De and Chen, Charlie and Mudgal, Sidharth and Stella, Romina and Brooks, Kevin and Vasudevan, Gautam and Liu, Chenxi and Chain, Mainak and Melinkeri, Nivedita and Cohen, Aaron and Wang, Venus and Seymore, Kristie and Zubkov, Sergey and Goel, Rahul and Yue, Summer and Krishnakumaran, Sai and Albert, Brian and Hurley, Nate and Sano, Motoki and Mohananey, Anhad and Joughin, Jonah and Filonov, Egor and Kępa, Tomasz and Eldawy, Yomna and Lim, Jiawern and Rishi, Rahul and Badiezadegan, Shirin and Bos, Taylor and Chang, Jerry and Jain, Sanil and Padmanabhan, Sri Gayatri Sundara and Puttagunta, Subha and Krishna, Kalpesh and Baker, Leslie and Kalb, Norbert and Bedapudi, Vamsi and Kurzrok, Adam and Lei, Shuntong and Yu, Anthony and Litvin, Oren and Zhou, Xiang and Wu, Zhichun and Sobell, Sam and Siciliano, Andrea and Papir, Alan and Neale, Robby and Bragagnolo, Jonas and Toor, Tej and Chen, Tina and Anklin, Valentin and Wang, Feiran and Feng, Richie and Gholami, Milad and Ling, Kevin and Liu, Lijuan and Walter, Jules and Moghaddam, Hamid and Kishore, Arun and Adamek, Jakub and Mercado, Tyler and Mallinson, Jonathan and Wandekar, Siddhinita and Cagle, Stephen and Ofek, Eran and Garrido, Guillermo and Lombriser, Clemens and Mukha, Maksim and Sun, Botu and Mohammad, Hafeezul Rahman and Matak, Josip and Qian, Yadi and Peswani, Vikas and Janus, Pawel and Yuan, Quan and Schelin, Leif and David, Oana and Garg, Ankur and He, Yifan and Duzhyi, Oleksii and Älgmyr, Anton and Lottaz, Timothée and Li, Qi and Yadav, Vikas and Xu, Luyao and Chinien, Alex and Shivanna, Rakesh and Chuklin, Aleksandr and Li, Josie and Spadine, Carrie and Wolfe, Travis and Mohamed, Kareem and Das, Subhabrata and Dai, Zihang and He, Kyle and Dincklage, Daniel von and Upadhyay, Shyam and Maurya, Akanksha and Chi, Luyan and Krause, Sebastian and Salama, Khalid and Rabinovitch, Pam G. and M, Pavan Kumar Reddy and Selvan, Aarush and Dektiarev, Mikhail and Ghiasi, Golnaz and Guven, Erdem and Gupta, Himanshu and Liu, Boyi and Sharma, Deepak and Shtacher, Idan Heimlich and Paul, Shachi and Akerlund, Oscar and Aubet, François-Xavier and Huang, Terry and Zhu, Chen and Zhu, Eric and Teixeira, Elico and Fritze, Matthew and Bertolini, Francesco and Marinescu, Liana-Eleonora and Bölle, Martin and Paulus, Dominik and Gupta, Khyatti and Latkar, Tejasi and Chang, Max and Sanders, Jason and Wilson, Roopa and Wu, Xuewei and Tan, Yi-Xuan and Thiet, Lam Nguyen and Doshi, Tulsee and Lall, Sid and Mishra, Swaroop and Chen, Wanming and Luong, Thang and Benjamin, Seth and Lee, Jasmine and Andrejczuk, Ewa and Rabiej, Dominik and Ranjan, Vipul and Styrc, Krzysztof and Yin, Pengcheng and Simon, Jon and Harriott, Malcolm Rose and Bansal, Mudit and Robsky, Alexei and Bacon, Geoff and Greene, David and Mirylenka, Daniil and Zhou, Chen and Sarvana, Obaid and Goyal, Abhimanyu and Andermatt, Samuel and Siegler, Patrick and Horn, Ben and Israel, Assaf and Pongetti, Francesco and Chen, Chih-Wei "Louis" and Selvatici, Marco and Silva, Pedro and Wang, Kathie and Tolins, Jackson and Guu, Kelvin and Yogev, Roey and Cai, Xiaochen and Agostini, Alessandro and Shah, Maulik and Nguyen, Hung and Donnaile, Noah Ó and Pereira, Sébastien and Friso, Linda and Stambler, Adam and Kurzrok, Adam and Kuang, Chenkai and Romanikhin, Yan and Geller, Mark and Yan, Z. J. and Jang, Kane and Lee, Cheng-Chun and Fica, Wojciech and Malmi, Eric and Tan, Qijun and Banica, Dan and Balle, Daniel and Pham, Ryan and Huang, Yanping and Avram, Diana and Shi, Hongzhi and Singh, Jasjot and Hidey, Chris and Ahuja, Niharika and Saxena, Pranab and Dooley, Dan and Potharaju, Srividya Pranavi and O'Neill, Eileen and Gokulchandran, Anand and Foley, Ryan and Zhao, Kai and Dusenberry, Mike and Liu, Yuan and Mehta, Pulkit and Kotikalapudi, Ragha and Safranek-Shrader, Chalence and Goodman, Andrew and Kessinger, Joshua and Globen, Eran and Kolhar, Prateek and Gorgolewski, Chris and Ibrahim, Ali and Song, Yang and Eichenbaum, Ali and Brovelli, Thomas and Potluri, Sahitya and Lahoti, Preethi and Baetu, Cip and Ghorbani, Ali and Chen, Charles and Crawford, Andy and Pal, Shalini and Sridhar, Mukund and Gurita, Petru and Mujika, Asier and Petrovski, Igor and Cedoz, Pierre-Louis and Li, Chenmei and Chen, Shiyuan and Santo, Niccolò Dal and Goyal, Siddharth and Punjabi, Jitesh and Kappaganthu, Karthik and Kwak, Chester and {LV}, Pallavi and Velury, Sarmishta and Choudhury, Himadri and Hall, Jamie and Shah, Premal and Figueira, Ricardo and Thomas, Matt and Lu, Minjie and Zhou, Ting and Kumar, Chintu and Jurdi, Thomas and Chikkerur, Sharat and Ma, Yenai and Yu, Adams and Kwak, Soo and Ähdel, Victor and Rajayogam, Sujeevan and Choma, Travis and Liu, Fei and Barua, Aditya and Ji, Colin and Park, Ji Ho and Hellendoorn, Vincent and Bailey, Alex and Bilal, Taylan and Zhou, Huanjie and Khatir, Mehrdad and Sutton, Charles and Rzadkowski, Wojciech and Macintosh, Fiona and Vij, Roopali and Shagin, Konstantin and Medina, Paul and Liang, Chen and Zhou, Jinjing and Shah, Pararth and Bi, Yingying and Dankovics, Attila and Banga, Shipra and Lehmann, Sabine and Bredesen, Marissa and Lin, Zifan and Hoffmann, John Eric and Lai, Jonathan and Chung, Raynald and Yang, Kai and Balani, Nihal and Bražinskas, Arthur and Sozanschi, Andrei and Hayes, Matthew and Alcalde, Héctor Fernández and Makarov, Peter and Chen, Will and Stella, Antonio and Snijders, Liselotte and Mandl, Michael and Kärrman, Ante and Nowak, Paweł and Wu, Xinyi and Dyck, Alex and Vaidyanathan, Krishnan and R, Raghavender and Mallet, Jessica and Rudominer, Mitch and Johnston, Eric and Mittal, Sushil and Udathu, Akhil and Christensen, Janara and Verma, Vishal and Irving, Zach and Santucci, Andreas and Elsayed, Gamaleldin and Davoodi, Elnaz and Georgiev, Marin and Tenney, Ian and Hua, Nan and Cideron, Geoffrey and Leurent, Edouard and Alnahlawi, Mahmoud and Georgescu, Ionut and Wei, Nan and Zheng, Ivy and Scandinaro, Dylan and Jiang, Heinrich and Snoek, Jasper and Sundararajan, Mukund and Wang, Xuezhi and Ontiveros, Zack and Karo, Itay and Cole, Jeremy and Rajashekhar, Vinu and Tumeh, Lara and Ben-David, Eyal and Jain, Rishub and Uesato, Jonathan and Datta, Romina and Bunyan, Oskar and Wu, Shimu and Zhang, John and Stanczyk, Piotr and Zhang, Ye and Steiner, David and Naskar, Subhajit and Azzam, Michael and Johnson, Matthew and Paszke, Adam and Chiu, Chung-Cheng and Elias, Jaume Sanchez and Mohiuddin, Afroz and Muhammad, Faizan and Miao, Jin and Lee, Andrew and Vieillard, Nino and Park, Jane and Zhang, Jiageng and Stanway, Jeff and Garmon, Drew and Karmarkar, Abhijit and Dong, Zhe and Lee, Jong and Kumar, Aviral and Zhou, Luowei and Evens, Jonathan and Isaac, William and Irving, Geoffrey and Loper, Edward and Fink, Michael and Arkatkar, Isha and Chen, Nanxin and Shafran, Izhak and Petrychenko, Ivan and Chen, Zhe and Jia, Johnson and Levskaya, Anselm and Zhu, Zhenkai and Grabowski, Peter and Mao, Yu and Magni, Alberto and Yao, Kaisheng and Snaider, Javier and Casagrande, Norman and Palmer, Evan and Suganthan, Paul and Castaño, Alfonso and Giannoumis, Irene and Kim, Wooyeol and Rybiński, Mikołaj and Sreevatsa, Ashwin and Prendki, Jennifer and Soergel, David and Goedeckemeyer, Adrian and Gierke, Willi and Jafari, Mohsen and Gaba, Meenu and Wiesner, Jeremy and Wright, Diana Gage and Wei, Yawen and Vashisht, Harsha and Kulizhskaya, Yana and Hoover, Jay and Le, Maigo and Li, Lu and Iwuanyanwu, Chimezie and Liu, Lu and Ramirez, Kevin and Khorlin, Andrey and Cui, Albert and {LIN}, Tian and Wu, Marcus and Aguilar, Ricardo and Pallo, Keith and Chakladar, Abhishek and Perng, Ginger and Abellan, Elena Allica and Zhang, Mingyang and Dasgupta, Ishita and Kushman, Nate and Penchev, Ivo and Repina, Alena and Wu, Xihui and Weide, Tom van der and Ponnapalli, Priya and Kaplan, Caroline and Simsa, Jiri and Li, Shuangfeng and Dousse, Olivier and Yang, Fan and Piper, Jeff and Ie, Nathan and Pasumarthi, Rama and Lintz, Nathan and Vijayakumar, Anitha and Andor, Daniel and Valenzuela, Pedro and Lui, Minnie and Paduraru, Cosmin and Peng, Daiyi and Lee, Katherine and Zhang, Shuyuan and Greene, Somer and Nguyen, Duc Dung and Kurylowicz, Paula and Hardin, Cassidy and Dixon, Lucas and Janzer, Lili and Choo, Kiam and Feng, Ziqiang and Zhang, Biao and Singhal, Achintya and Du, Dayou and {McKinnon}, Dan and Antropova, Natasha and Bolukbasi, Tolga and Keller, Orgad and Reid, David and Finchelstein, Daniel and Raad, Maria Abi and Crocker, Remi and Hawkins, Peter and Dadashi, Robert and Gaffney, Colin and Franko, Ken and Bulanova, Anna and Leblond, Rémi and Chung, Shirley and Askham, Harry and Cobo, Luis C. and Xu, Kelvin and Fischer, Felix and Xu, Jun and Sorokin, Christina and Alberti, Chris and Lin, Chu-Cheng and Evans, Colin and Dimitriev, Alek and Forbes, Hannah and Banarse, Dylan and Tung, Zora and Omernick, Mark and Bishop, Colton and Sterneck, Rachel and Jain, Rohan and Xia, Jiawei and Amid, Ehsan and Piccinno, Francesco and Wang, Xingyu and Banzal, Praseem and Mankowitz, Daniel J. and Polozov, Alex and Krakovna, Victoria and Brown, Sasha and Bateni, {MohammadHossein} and Duan, Dennis and Firoiu, Vlad and Thotakuri, Meghana and Natan, Tom and Geist, Matthieu and Girgin, Ser tan and Li, Hui and Ye, Jiayu and Roval, Ofir and Tojo, Reiko and Kwong, Michael and Lee-Thorp, James and Yew, Christopher and Sinopalnikov, Danila and Ramos, Sabela and Mellor, John and Sharma, Abhishek and Wu, Kathy and Miller, David and Sonnerat, Nicolas and Vnukov, Denis and Greig, Rory and Beattie, Jennifer and Caveness, Emily and Bai, Libin and Eisenschlos, Julian and Korchemniy, Alex and Tsai, Tomy and Jasarevic, Mimi and Kong, Weize and Dao, Phuong and Zheng, Zeyu and Liu, Frederick and Yang, Fan and Zhu, Rui and Teh, Tian Huey and Sanmiya, Jason and Gladchenko, Evgeny and Trdin, Nejc and Toyama, Daniel and Rosen, Evan and Tavakkol, Sasan and Xue, Linting and Elkind, Chen and Woodman, Oliver and Carpenter, John and Papamakarios, George and Kemp, Rupert and Kafle, Sushant and Grunina, Tanya and Sinha, Rishika and Talbert, Alice and Wu, Diane and Owusu-Afriyie, Denese and Du, Cosmo and Thornton, Chloe and Pont-Tuset, Jordi and Narayana, Pradyumna and Li, Jing and Fatehi, Saaber and Wieting, John and Ajmeri, Omar and Uria, Benigno and Ko, Yeongil and Knight, Laura and Héliou, Amélie and Niu, Ning and Gu, Shane and Pang, Chenxi and Li, Yeqing and Levine, Nir and Stolovich, Ariel and Santamaria-Fernandez, Rebeca and Goenka, Sonam and Yustalim, Wenny and Strudel, Robin and Elqursh, Ali and Deck, Charlie and Lee, Hyo and Li, Zonglin and Levin, Kyle and Hoffmann, Raphael and Holtmann-Rice, Dan and Bachem, Olivier and Arora, Sho and Koh, Christy and Yeganeh, Soheil Hassas and Põder, Siim and Tariq, Mukarram and Sun, Yanhua and Ionita, Lucian and Seyedhosseini, Mojtaba and Tafti, Pouya and Liu, Zhiyu and Gulati, Anmol and Liu, Jasmine and Ye, Xinyu and Chrzaszcz, Bart and Wang, Lily and Sethi, Nikhil and Li, Tianrun and Brown, Ben and Singh, Shreya and Fan, Wei and Parisi, Aaron and Stanton, Joe and Koverkathu, Vinod and Choquette-Choo, Christopher A. and Li, Yunjie and Lu, T. J. and Ittycheriah, Abe and Shroff, Prakash and Varadarajan, Mani and Bahargam, Sanaz and Willoughby, Rob and Gaddy, David and Desjardins, Guillaume and Cornero, Marco and Robenek, Brona and Mittal, Bhavishya and Albrecht, Ben and Shenoy, Ashish and Moiseev, Fedor and Jacobsson, Henrik and Ghaffarkhah, Alireza and Rivière, Morgane and Walton, Alanna and Crepy, Clément and Parrish, Alicia and Zhou, Zongwei and Farabet, Clement and Radebaugh, Carey and Srinivasan, Praveen and Salm, Claudia van der and Fidjeland, Andreas and Scellato, Salvatore and Latorre-Chimoto, Eri and Klimczak-Plucińska, Hanna and Bridson, David and Cesare, Dario de and Hudson, Tom and Mendolicchio, Piermaria and Walker, Lexi and Morris, Alex and Mauger, Matthew and Guseynov, Alexey and Reid, Alison and Odoom, Seth and Loher, Lucia and Cotruta, Victor and Yenugula, Madhavi and Grewe, Dominik and Petrushkina, Anastasia and Duerig, Tom and Sanchez, Antonio and Yadlowsky, Steve and Shen, Amy and Globerson, Amir and Webb, Lynette and Dua, Sahil and Li, Dong and Bhupatiraju, Surya and Hurt, Dan and Qureshi, Haroon and Agarwal, Ananth and Shani, Tomer and Eyal, Matan and Khare, Anuj and Belle, Shreyas Rammohan and Wang, Lei and Tekur, Chetan and Kale, Mihir Sanjay and Wei, Jinliang and Sang, Ruoxin and Saeta, Brennan and Liechty, Tyler and Sun, Yi and Zhao, Yao and Lee, Stephan and Nayak, Pandu and Fritz, Doug and Vuyyuru, Manish Reddy and Aslanides, John and Vyas, Nidhi and Wicke, Martin and Ma, Xiao and Eltyshev, Evgenii and Martin, Nina and Cate, Hardie and Manyika, James and Amiri, Keyvan and Kim, Yelin and Xiong, Xi and Kang, Kai and Luisier, Florian and Tripuraneni, Nilesh and Madras, David and Guo, Mandy and Waters, Austin and Wang, Oliver and Ainslie, Joshua and Baldridge, Jason and Zhang, Han and Pruthi, Garima and Bauer, Jakob and Yang, Feng and Mansour, Riham and Gelman, Jason and Xu, Yang and Polovets, George and Liu, Ji and Cai, Honglong and Chen, Warren and Sheng, {XiangHai} and Xue, Emily and Ozair, Sherjil and Angermueller, Christof and Li, Xiaowei and Sinha, Anoop and Wang, Weiren and Wiesinger, Julia and Koukoumidis, Emmanouil and Tian, Yuan and Iyer, Anand and Gurumurthy, Madhu and Goldenson, Mark and Shah, Parashar and Blake, M. K. and Yu, Hongkun and Urbanowicz, Anthony and Palomaki, Jennimaria and Fernando, Chrisantha and Durden, Ken and Mehta, Harsh and Momchev, Nikola and Rahimtoroghi, Elahe and Georgaki, Maria and Raul, Amit and Ruder, Sebastian and Redshaw, Morgan and Lee, Jinhyuk and Zhou, Denny and Jalan, Komal and Li, Dinghua and Hechtman, Blake and Schuh, Parker and Nasr, Milad and Milan, Kieran and Mikulik, Vladimir and Franco, Juliana and Green, Tim and Nguyen, Nam and Kelley, Joe and Mahendru, Aroma and Hu, Andrea and Howland, Joshua and Vargas, Ben and Hui, Jeffrey and Bansal, Kshitij and Rao, Vikram and Ghiya, Rakesh and Wang, Emma and Ye, Ke and Sarr, Jean Michel and Preston, Melanie Moranski and Elish, Madeleine and Li, Steve and Kaku, Aakash and Gupta, Jigar and Pasupat, Ice and Juan, Da-Cheng and Someswar, Milan and M, Tejvi and Chen, Xinyun and Amini, Aida and Fabrikant, Alex and Chu, Eric and Dong, Xuanyi and Muthal, Amruta and Buthpitiya, Senaka and Jauhari, Sarthak and Hua, Nan and Khandelwal, Urvashi and Hitron, Ayal and Ren, Jie and Rinaldi, Larissa and Drath, Shahar and Dabush, Avigail and Jiang, Nan-Jiang and Godhia, Harshal and Sachs, Uli and Chen, Anthony and Fan, Yicheng and Taitelbaum, Hagai and Noga, Hila and Dai, Zhuyun and Wang, James and Liang, Chen and Hamer, Jenny and Ferng, Chun-Sung and Elkind, Chenel and Atias, Aviel and Lee, Paulina and Listík, Vít and Carlen, Mathias and Kerkhof, Jan van de and Pikus, Marcin and Zaher, Krunoslav and Müller, Paul and Zykova, Sasha and Stefanec, Richard and Gatsko, Vitaly and Hirnschall, Christoph and Sethi, Ashwin and Xu, Xingyu Federico and Ahuja, Chetan and Tsai, Beth and Stefanoiu, Anca and Feng, Bo and Dhandhania, Keshav and Katyal, Manish and Gupta, Akshay and Parulekar, Atharva and Pitta, Divya and Zhao, Jing and Bhatia, Vivaan and Bhavnani, Yashodha and Alhadlaq, Omar and Li, Xiaolin and Danenberg, Peter and Tu, Dennis and Pine, Alex and Filippova, Vera and Ghosh, Abhipso and Limonchik, Ben and Urala, Bhargava and Lanka, Chaitanya Krishna and Clive, Derik and Sun, Yi and Li, Edward and Wu, Hao and Hongtongsak, Kevin and Li, Ianna and Thakkar, Kalind and Omarov, Kuanysh and Majmundar, Kushal and Alverson, Michael and Kucharski, Michael and Patel, Mohak and Jain, Mudit and Zabelin, Maksim and Pelagatti, Paolo and Kohli, Rohan and Kumar, Saurabh and Kim, Joseph and Sankar, Swetha and Shah, Vineet and Ramachandruni, Lakshmi and Zeng, Xiangkai and Bariach, Ben and Weidinger, Laura and Vu, Tu and Andreev, Alek and He, Antoine and Hui, Kevin and Kashem, Sheleem and Subramanya, Amar and Hsiao, Sissie and Hassabis, Demis and Kavukcuoglu, Koray and Sadovsky, Adam and Le, Quoc and Strohman, Trevor and Wu, Yonghui and Petrov, Slav and Dean, Jeffrey and Vinyals, Oriol},
	urldate = {2026-01-08},
	date = {2025-05-09},
	eprinttype = {arxiv},
	eprint = {2312.11805 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/RICCPNR3/Team et al. - 2025 - Gemini A Family of Highly Capable Multimodal Models.pdf:application/pdf},
}

@misc{kirillov_segment_2023,
	title = {Segment Anything},
	url = {http://arxiv.org/abs/2304.02643},
	doi = {10.48550/arXiv.2304.02643},
	abstract = {We introduce the Segment Anything ({SA}) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model ({SAM}) and corresponding dataset ({SA}-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	number = {{arXiv}:2304.02643},
	publisher = {{arXiv}},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	urldate = {2026-01-08},
	date = {2023-04-05},
	eprinttype = {arxiv},
	eprint = {2304.02643 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/JSW7CDNL/Kirillov et al. - 2023 - Segment Anything.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/S5P7ISVX/2304.html:text/html},
}

@misc{rombach_high-resolution_2022,
	title = {High-Resolution Image Synthesis with Latent Diffusion Models},
	url = {http://arxiv.org/abs/2112.10752},
	doi = {10.48550/arXiv.2112.10752},
	abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models ({DMs}) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful {DMs} often consumes hundreds of {GPU} days and inference is expensive due to sequential evaluations. To enable {DM} training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models ({LDMs}) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based {DMs}. Code is available at https://github.com/{CompVis}/latent-diffusion .},
	number = {{arXiv}:2112.10752},
	publisher = {{arXiv}},
	author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
	urldate = {2026-01-08},
	date = {2022-04-13},
	eprinttype = {arxiv},
	eprint = {2112.10752 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/V3MWTMUN/Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffusion Models.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/KQUEMLNT/2112.html:text/html},
}

@misc{kreps_all_2020,
	location = {Rochester, {NY}},
	title = {All the News that’s Fit to Fabricate: {AI}-Generated Text as a Tool of Media Misinformation},
	url = {https://papers.ssrn.com/abstract=3525002},
	doi = {10.2139/ssrn.3525002},
	shorttitle = {All the News that’s Fit to Fabricate},
	abstract = {Online misinformation has become a constant; only the way actors create and distribute that information is changing. Advances in artificial intelligence ({AI}) mean that actors can now synthetically generate text in ways that mimic the style and substance of human-created news stories. We carried out three original experiments to study whether these {AI}-generated texts are credible and can influence opinions on foreign policy — a likely target of real-world misinformation. The first evaluated human detection of {AI}-generated text relative to the original story from which it was generated. The second examined the credibility distribution across different model sizes to gauge whether improvements in processing produce commensurate increases in credibility. The third investigated the interaction between partisanship and {AI}-generated news. We find that individuals are largely incapable of distinguishing between {AI} and human-generated text; partisanship affects the perceived credibility of the story; and exposure to the text does little to change individuals’ policy views. The findings have important implications for the way malicious actors might employ {AI} in online misinformation campaigns and electoral interference.},
	number = {3525002},
	publisher = {Social Science Research Network},
	author = {Kreps, Sarah E. and {McCain}, Miles and Brundage, Miles},
	urldate = {2026-01-08},
	date = {2020-09-24},
	langid = {english},
	keywords = {All the News that’s Fit to Fabricate: {AI}-Generated Text as a Tool of Media Misinformation, Miles Brundage, Miles {McCain}, Sarah E. Kreps, {SSRN}},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/BANK7X7A/Kreps et al. - 2020 - All the News that’s Fit to Fabricate AI-Generated Text as a Tool of Media Misinformation.pdf:application/pdf},
}

@misc{devlin_bert_2019,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5\% (7.7\% point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	number = {{arXiv}:1810.04805},
	publisher = {{arXiv}},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2026-01-08},
	date = {2019-05-24},
	eprinttype = {arxiv},
	eprint = {1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/NFB4VSPE/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/3V5QHQEB/1810.html:text/html},
}

@misc{maronikolakis_identifying_2021,
	title = {Identifying Automatically Generated Headlines using Transformers},
	url = {http://arxiv.org/abs/2009.13375},
	doi = {10.48550/arXiv.2009.13375},
	abstract = {False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation. To this end, a dataset containing human and computer-generated headlines was created and a user study indicated that humans were only able to identify the fake headlines in 47.8\% of the cases. However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7\%, indicating that content generated from language models can be filtered out accurately.},
	number = {{arXiv}:2009.13375},
	publisher = {{arXiv}},
	author = {Maronikolakis, Antonis and Schutze, Hinrich and Stevenson, Mark},
	urldate = {2026-01-08},
	date = {2021-04-25},
	eprinttype = {arxiv},
	eprint = {2009.13375 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Computers and Society},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/S6UY3W75/Maronikolakis et al. - 2021 - Identifying Automatically Generated Headlines using Transformers.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/U2AH3EPE/2009.html:text/html},
}

@article{jwa_exbake_2019,
	title = {{exBAKE}: Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Transformers ({BERT})},
	volume = {9},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/9/19/4062},
	doi = {10.3390/app9194062},
	shorttitle = {{exBAKE}},
	abstract = {News currently spreads rapidly through the internet. Because fake news stories are designed to attract readers, they tend to spread faster. For most readers, detecting fake news can be challenging and such readers usually end up believing that the fake news story is fact. Because fake news can be socially problematic, a model that automatically detects such fake news is required. In this paper, we focus on data-driven automatic fake news detection methods. We first apply the Bidirectional Encoder Representations from Transformers model ({BERT}) model to detect fake news by analyzing the relationship between the headline and the body text of news. To further improve performance, additional news data are gathered and used to pre-train this model. We determine that the deep-contextualizing nature of {BERT} is best suited for this task and improves the 0.14 F-score over older state-of-the-art models.},
	pages = {4062},
	number = {19},
	journaltitle = {Applied Sciences},
	author = {Jwa, Heejung and Oh, Dongsuk and Park, Kinam and Kang, Jang Mook and Lim, Heuiseok},
	urldate = {2026-01-08},
	date = {2019-01},
	langid = {english},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, fake information, fake news, fake news challenge, fake news classification, fake news detect},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/6DMKX77L/Jwa et al. - 2019 - exBAKE Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Tran.pdf:application/pdf},
}

@misc{mosallanezhad_topic-preserving_2020,
	title = {Topic-Preserving Synthetic News Generation: An Adversarial Deep Reinforcement Learning Approach},
	url = {http://arxiv.org/abs/2010.16324},
	doi = {10.48550/arXiv.2010.16324},
	shorttitle = {Topic-Preserving Synthetic News Generation},
	abstract = {Nowadays, there exist powerful language models such as {OpenAI}'s {GPT}-2 that can generate readable text and can be fine-tuned to generate text for a specific domain. Considering {GPT}-2, it cannot directly generate synthetic news with respect to a given topic and the output of the language model cannot be explicitly controlled. In this paper, we study the novel problem of topic-preserving synthetic news generation. We propose a novel deep reinforcement learning-based method to control the output of {GPT}-2 with respect to a given news topic. When generating text using {GPT}-2, by default, the most probable word is selected from the vocabulary. Instead of selecting the best word each time from {GPT}-2's output, an {RL} agent tries to select words that optimize the matching of a given topic. In addition, using a fake news detector as an adversary, we investigate generating realistic news using our proposed method. In this paper, we consider realistic news as news that cannot be easily detected by a fake news classifier. Experimental results demonstrate the effectiveness of the proposed framework on generating topic-preserving news content than state-of-the-art baselines.},
	number = {{arXiv}:2010.16324},
	publisher = {{arXiv}},
	author = {Mosallanezhad, Ahmadreza and Shu, Kai and Liu, Huan},
	urldate = {2026-01-08},
	date = {2020-10-30},
	eprinttype = {arxiv},
	eprint = {2010.16324 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/BEX2EHCY/Mosallanezhad et al. - 2020 - Topic-Preserving Synthetic News Generation An Adversarial Deep Reinforcement Learning Approach.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/G5WLTPVZ/2010.html:text/html},
}

@incollection{foresti_unveiling_2023,
	location = {Cham},
	title = {Unveiling the Impact of Image Transformations on Deepfake Detection: An Experimental Analysis},
	volume = {14234},
	isbn = {978-3-031-43152-4 978-3-031-43153-1},
	url = {https://link.springer.com/10.1007/978-3-031-43153-1_29},
	shorttitle = {Unveiling the Impact of Image Transformations on Deepfake Detection},
	abstract = {With the recent explosion of interest in visual Generative {AI}, the field of deepfake detection has gained a lot of attention. In fact, deepfake detection might be the only measure to counter the potential proliferation of generated media in support of fake news and its consequences. While many of the available works limit the detection to a pure and direct classification of fake versus real, this does not translate well to a real-world scenario. Indeed, malevolent users can easily apply post-processing techniques to generated content, changing the underlying distribution of fake data. In this work, we provide an in-depth analysis of the robustness of a deepfake detection pipeline, considering different image augmentations, transformations, and other pre-processing steps. These transformations are only applied in the evaluation phase, thus simulating a practical situation in which the detector is not trained on all the possible augmentations that can be used by the attacker. In particular, we analyze the performance of a k-{NN} and a linear probe detector on the {COCOFake} dataset, using image features extracted from pre-trained models, like {CLIP} and {DINO}. Our results demonstrate that while the {CLIP} visual backbone outperforms {DINO} in deepfake detection with no augmentation, its performance varies significantly in presence of any transformation, favoring the robustness of {DINO}.},
	pages = {345--356},
	booktitle = {Image Analysis and Processing – {ICIAP} 2023},
	publisher = {Springer Nature Switzerland},
	author = {Cocchi, Federico and Baraldi, Lorenzo and Poppi, Samuele and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
	editor = {Foresti, Gian Luca and Fusiello, Andrea and Hancock, Edwin},
	urldate = {2026-01-08},
	date = {2023},
	langid = {english},
	doi = {10.1007/978-3-031-43153-1_29},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {PDF:/home/mhetac/Zotero/storage/FWL732LE/Cocchi et al. - 2023 - Unveiling the Impact of Image Transformations on Deepfake Detection An Experimental Analysis.pdf:application/pdf},
}

@inproceedings{schutz_automatic_2021,
	location = {Cham},
	title = {Automatic Fake News Detection with Pre-trained Transformer Models},
	isbn = {978-3-030-68787-8},
	doi = {10.1007/978-3-030-68787-8_45},
	abstract = {The automatic detection of disinformation and misinformation has gained attention during the last years, since fake news has a critical impact on democracy, society, and journalism and digital literacy. In this paper, we present a binary content-based classification approach for detecting fake news automatically, with several recently published pre-trained language models based on the Transformer architecture. The experiments were conducted on the {FakeNewsNet} dataset with {XLNet}, {BERT}, {RoBERTa}, {DistilBERT}, and {ALBERT} and various combinations of hyperparameters. Different preprocessing steps were carried out with only using the body text, the titles and a concatenation of both. It is concluded that Transformers are a promising approach to detect fake news, since they achieve notable results, even without using a large dataset. Our main contribution is the enhancement of fake news’ detection accuracy through different models and parametrizations with a reproducible result examination through the conducted experiments. The evaluation shows that already short texts are enough to attain 85\% accuracy on the test set. Using the body text and a concatenation of both reach up to 87\% accuracy. Lastly, we show that various preprocessing steps, such as removing outliers, do not have a significant impact on the models prediction output.},
	pages = {627--641},
	booktitle = {Pattern Recognition. {ICPR} International Workshops and Challenges},
	publisher = {Springer International Publishing},
	author = {Schütz, Mina and Schindler, Alexander and Siegel, Melanie and Nazemi, Kawa},
	editor = {Del Bimbo, Alberto and Cucchiara, Rita and Sclaroff, Stan and Farinella, Giovanni Maria and Mei, Tao and Bertini, Marco and Escalante, Hugo Jair and Vezzani, Roberto},
	date = {2021},
	langid = {english},
	keywords = {{BERT}, Fake news, Fake news detection, Pre-trained language model, Transformer},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/CPEAPPUD/Schütz et al. - 2021 - Automatic Fake News Detection with Pre-trained Transformer Models.pdf:application/pdf},
}

@article{ferrara_genai_2024,
	title = {{GenAI} against humanity: nefarious applications of generative artificial intelligence and large language models},
	volume = {7},
	issn = {2432-2725},
	url = {https://doi.org/10.1007/s42001-024-00250-1},
	doi = {10.1007/s42001-024-00250-1},
	shorttitle = {{GenAI} against humanity},
	abstract = {Generative Artificial Intelligence ({GenAI}) and Large Language Models ({LLMs}) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of {GenAI} applications. This article is not just a journey through the meanders of potential misuse of {GenAI} and {LLMs}, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we’ll uncover the societal implications that ripple through the {GenAI} revolution we are witnessing. From {AI}-powered botnets on social media platforms to the unnerving potential of {AI} to generate fabricated identities, or alibis made of synthetic realities, the stakes have never been higher. The lines between the virtual and the real worlds are blurring, and the consequences of potential {GenAI}’s nefarious applications impact us all. This article serves both as a synthesis of rigorous research presented on the risks of {GenAI} and misuse of {LLMs} and as a thought-provoking vision of the different types of harmful {GenAI} applications we might encounter in the near future, and some ways we can prepare for them.},
	pages = {549--569},
	number = {1},
	journaltitle = {J Comput Soc Sc},
	author = {Ferrara, Emilio},
	urldate = {2026-01-08},
	date = {2024-04-01},
	langid = {english},
	keywords = {{AI}, Generative {AI}, Large Language Models, Risks, Social media},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/XT7STRJR/Ferrara - 2024 - GenAI against humanity nefarious applications of generative artificial intelligence and large langu.pdf:application/pdf},
}

@misc{maronikolakis_identifying_2021-1,
	title = {Identifying Automatically Generated Headlines using Transformers},
	url = {http://arxiv.org/abs/2009.13375},
	doi = {10.48550/arXiv.2009.13375},
	abstract = {False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation. To this end, a dataset containing human and computer-generated headlines was created and a user study indicated that humans were only able to identify the fake headlines in 47.8\% of the cases. However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7\%, indicating that content generated from language models can be filtered out accurately.},
	number = {{arXiv}:2009.13375},
	publisher = {{arXiv}},
	author = {Maronikolakis, Antonis and Schutze, Hinrich and Stevenson, Mark},
	urldate = {2026-01-08},
	date = {2021-04-25},
	eprinttype = {arxiv},
	eprint = {2009.13375 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Computers and Society},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/YAMWHU9X/Maronikolakis et al. - 2021 - Identifying Automatically Generated Headlines using Transformers.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/3TB65SB8/2009.html:text/html},
}

@misc{vijjali_two_2020,
	title = {Two Stage Transformer Model for {COVID}-19 Fake News Detection and Fact Checking},
	url = {http://arxiv.org/abs/2011.13253},
	doi = {10.48550/arXiv.2011.13253},
	abstract = {The rapid advancement of technology in online communication via social media platforms has led to a prolific rise in the spread of misinformation and fake news. Fake news is especially rampant in the current {COVID}-19 pandemic, leading to people believing in false and potentially harmful claims and stories. Detecting fake news quickly can alleviate the spread of panic, chaos and potential health hazards. We developed a two stage automated pipeline for {COVID}-19 fake news detection using state of the art machine learning models for natural language processing. The first model leverages a novel fact checking algorithm that retrieves the most relevant facts concerning user claims about particular {COVID}-19 claims. The second model verifies the level of truth in the claim by computing the textual entailment between the claim and the true facts retrieved from a manually curated {COVID}-19 dataset. The dataset is based on a publicly available knowledge source consisting of more than 5000 {COVID}-19 false claims and verified explanations, a subset of which was internally annotated and cross-validated to train and evaluate our models. We evaluate a series of models based on classical text-based features to more contextual Transformer based models and observe that a model pipeline based on {BERT} and {ALBERT} for the two stages respectively yields the best results.},
	number = {{arXiv}:2011.13253},
	publisher = {{arXiv}},
	author = {Vijjali, Rutvik and Potluri, Prathyush and Kumar, Siddharth and Teki, Sundeep},
	urldate = {2026-01-08},
	date = {2020-11-26},
	eprinttype = {arxiv},
	eprint = {2011.13253 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Information Retrieval},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/ZHA9PLFJ/Vijjali et al. - 2020 - Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/4NT3HN3C/2011.html:text/html},
}

@article{verma_one_2024,
	title = {“One Video Could Start a War”: A Qualitative Interview Study of Public Perceptions of Deepfake Technology},
	volume = {61},
	url = {https://doi.org/10.1002/pra2.1035},
	doi = {10.1002/pra2.1035},
	shorttitle = {“One Video Could Start a War”},
	abstract = {What is the public's perception of deepfake technology's impact on society? This study reports findings from a reflexive thematic analysis of qualitative interviews with 33 {US} adults. Among the themes that represent participants' perception of the technology's impact on society, the following most salient themes are reported: increase in political misinformation; increased political and ideological polarization of society; increase in the number of conspiratorial videos; increased potential of harm to marginalized groups and individuals; and children's vulnerability to being deceived via deepfakes. In addition, a summary theme collating public perspectives on positive implications of deepfake technology is presented. This study lays the groundwork for further qualitative and quantitative investigations of deepfake technology's impact on society as understood from the perspective of society's foremost constituents—people.},
	pages = {374--385},
	number = {1},
	journaltitle = {Proceedings of the Association for Information Science and Technology},
	author = {Verma, Nitin},
	urldate = {2026-01-08},
	date = {2024-10-15},
}

@inproceedings{bansal_deepfake_2023,
	title = {Deepfake Detection Using {CNN} and {DCGANS} to Drop-Out Fake Multimedia Content: A Hybrid Approach},
	url = {https://ieeexplore.ieee.org/document/10263628},
	doi = {10.1109/ICICAT57735.2023.10263628},
	shorttitle = {Deepfake Detection Using {CNN} and {DCGANS} to Drop-Out Fake Multimedia Content},
	abstract = {The creation of Deep Fakes, which are altered videos, audio, and photographs capable of disseminating false information and fake news and modifying sensitive records, is the result of the rapid advancements in artificial intelligence and machine learning. {DeepFakes} may also be used for interactive learning and visual effects in entertainment and education. As a result, numerous deep learning models, such as Convolutional Neural Networks ({CNN}) and Generative Adversarial Networks ({GAN}), are being used for detection. {DeepFakes} detection and removal have become essential challenges. Facebook {AI}'s Deepfake Detection Challenge ({DFDC}) dataset is invaluable for developing and evaluating detection techniques. While it represents serious risks, creating trustworthy detection techniques might lessen their impact and enable investigation of their possible beneficial applications. To ensure the authenticity and dependability of multimedia information in the face of the ongoing {DeepFake} threat, this paper emphasizes the importance of transfer learning, deep learning, and optimization techniques in building effective detection models. By doing this, we can stop the spread of fake news and information, protect the public's trust, and promote the moral and beneficial application of {DeepFake} technology across various fields.},
	eventtitle = {2023 International Conference on {IoT}, Communication and Automation Technology ({ICICAT})},
	pages = {1--6},
	booktitle = {2023 International Conference on {IoT}, Communication and Automation Technology ({ICICAT})},
	author = {Bansal, Kartik and Agarwal, Shubhi and Vyas, Narayan},
	urldate = {2026-01-08},
	date = {2023-06},
	keywords = {Convolutional Neural Networks ({CNN}), Deep learning, Deep Learning, Deepfakes, Education, Ethics, Generative adversarial networks, Image Classification, {ImageNet}, Optimization Techniques, Transfer learning, Transfer Learning, Visual effects},
}

@online{silverman_this_2016,
	title = {This Analysis Shows How Viral Fake Election News Stories Outperformed Real News On Facebook},
	url = {https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook},
	abstract = {A {BuzzFeed} News analysis found that top fake election news stories generated more total engagement on Facebook than top election stories from 19 major news outlets combined.},
	titleaddon = {{BuzzFeed} News},
	author = {Silverman, Craig},
	urldate = {2026-01-08},
	date = {2016-11-16},
	langid = {english},
	note = {Section: {USNews}},
}

@inproceedings{feng_syntactic_2012,
	location = {Jeju Island, Korea},
	title = {Syntactic Stylometry for Deception Detection},
	url = {https://aclanthology.org/P12-2034/},
	eventtitle = {{ACL} 2012},
	pages = {171--175},
	booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Feng, Song and Banerjee, Ritwik and Choi, Yejin},
	editor = {Li, Haizhou and Lin, Chin-Yew and Osborne, Miles and Lee, Gary Geunbae and Park, Jong C.},
	urldate = {2026-01-08},
	date = {2012-07},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/NGAHZ7QP/Feng et al. - 2012 - Syntactic Stylometry for Deception Detection.pdf:application/pdf},
}

@article{diresta_ai-generated_2020,
	title = {{AI}-Generated Text Is the Scariest Deepfake of All},
	issn = {1059-1028},
	url = {https://www.wired.com/story/ai-generated-text-is-the-scariest-deepfake-of-all/},
	abstract = {Synthetic video and audio seemed pretty bad. Synthetic writing—ubiquitous and undetectable—will be far worse.},
	journaltitle = {Wired},
	author = {{DiResta}, Renee},
	urldate = {2026-01-08},
	date = {2020-07-31},
	langid = {american},
	note = {Section: tags},
	keywords = {social media, fake news, artificial intelligence, deepfakes},
}

@article{rozado_political_2023,
	title = {The Political Biases of {ChatGPT}},
	volume = {12},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-0760},
	url = {https://www.mdpi.com/2076-0760/12/3/148},
	doi = {10.3390/socsci12030148},
	abstract = {Recent advancements in Large Language Models ({LLMs}) suggest imminent commercial applications of such {AI} systems where they will serve as gateways to interact with technology and the accumulated body of human knowledge. The possibility of political biases embedded in these models raises concerns about their potential misusage. In this work, we report the results of administering 15 different political orientation tests (14 in English, 1 in Spanish) to a state-of-the-art Large Language Model, the popular {ChatGPT} from {OpenAI}. The results are consistent across tests; 14 of the 15 instruments diagnose {ChatGPT} answers to their questions as manifesting a preference for left-leaning viewpoints. When asked explicitly about its political preferences, {ChatGPT} often claims to hold no political opinions and to just strive to provide factual and neutral information. It is desirable that public facing artificial intelligence systems provide accurate and factual information about empirically verifiable issues, but such systems should strive for political neutrality on largely normative questions for which there is no straightforward way to empirically validate a viewpoint. Thus, ethical {AI} systems should present users with balanced arguments on the issue at hand and avoid claiming neutrality while displaying clear signs of political bias in their content.},
	pages = {148},
	number = {3},
	journaltitle = {Social Sciences},
	author = {Rozado, David},
	urldate = {2026-01-08},
	date = {2023-03},
	langid = {english},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{AI}, algorithmic bias, {ChatGPT}, large language models, {LLMs}, {OpenAI}, political bias},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/VQ5UDQR2/Rozado - 2023 - The Political Biases of ChatGPT.pdf:application/pdf},
}

@article{rozado_political_2024,
	title = {The political preferences of {LLMs}},
	volume = {19},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0306621},
	doi = {10.1371/journal.pone.0306621},
	abstract = {I report here a comprehensive analysis about the political preferences embedded in Large Language Models ({LLMs}). Namely, I administer 11 political orientation tests, designed to identify the political preferences of the test taker, to 24 state-of-the-art conversational {LLMs}, both closed and open source. When probed with questions/statements with political connotations, most conversational {LLMs} tend to generate responses that are diagnosed by most political test instruments as manifesting preferences for left-of-center viewpoints. This does not appear to be the case for five additional base (i.e. foundation) models upon which {LLMs} optimized for conversation with humans are built. However, the weak performance of the base models at coherently answering the tests’ questions makes this subset of results inconclusive. Finally, I demonstrate that {LLMs} can be steered towards specific locations in the political spectrum through Supervised Fine-Tuning ({SFT}) with only modest amounts of politically aligned data, suggesting {SFT}’s potential to embed political orientation in {LLMs}. With {LLMs} beginning to partially displace traditional information sources like search engines and Wikipedia, the societal implications of political biases embedded in {LLMs} are substantial.},
	pages = {e0306621},
	number = {7},
	journaltitle = {{PLOS} {ONE}},
	author = {Rozado, David},
	urldate = {2026-01-08},
	date = {2024-07-31},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Culture, Human learning, Information retrieval, Language, Online encyclopedias, Political parties, User interfaces, Verbal communication},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/XG5RHX7E/Rozado - 2024 - The political preferences of LLMs.pdf:application/pdf},
}

@article{clark_extending_2025,
	title = {Extending Minds with Generative {AI}},
	volume = {16},
	rights = {2025 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-025-59906-9},
	doi = {10.1038/s41467-025-59906-9},
	abstract = {As human-{AI} collaborations become the norm, we should remind ourselves that it is our basic nature to build hybrid thinking systems – ones that fluidly incorporate non-biological resources. Recognizing this invites us to change the way we think about both the threats and promises of the coming age.},
	pages = {4627},
	number = {1},
	journaltitle = {Nat Commun},
	author = {Clark, Andy},
	urldate = {2026-01-08},
	date = {2025-05-19},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Intelligence, Interdisciplinary studies},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/JLNPIZ35/Clark - 2025 - Extending Minds with Generative AI.pdf:application/pdf},
}

@article{hohenstein_artificial_2023,
	title = {Artificial intelligence in communication impacts language and social relationships},
	volume = {13},
	rights = {2023 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-30938-9},
	doi = {10.1038/s41598-023-30938-9},
	abstract = {Artificial intelligence ({AI}) is already widely used in daily communication, but despite concerns about {AI}’s negative effects on society the social consequences of using it to communicate remain largely unexplored. We investigate the social consequences of one of the most pervasive {AI} applications, algorithmic response suggestions (“smart replies”), which are used to send billions of messages each day. Two randomized experiments provide evidence that these types of algorithmic recommender systems change how people interact with and perceive one another in both pro-social and anti-social ways. We find that using algorithmic responses changes language and social relationships. More specifically, it increases communication speed, use of positive emotional language, and conversation partners evaluate each other as closer and more cooperative. However, consistent with common assumptions about the adverse effects of {AI}, people are evaluated more negatively if they are suspected to be using algorithmic responses. Thus, even though {AI} can increase the speed of communication and improve interpersonal perceptions, the prevailing anti-social connotations of {AI} undermine these potential benefits if used overtly.},
	pages = {5487},
	number = {1},
	journaltitle = {Sci Rep},
	author = {Hohenstein, Jess and Kizilcec, Rene F. and {DiFranzo}, Dominic and Aghajari, Zhila and Mieczkowski, Hannah and Levy, Karen and Naaman, Mor and Hancock, Jeffrey and Jung, Malte F.},
	urldate = {2026-01-08},
	date = {2023-04-04},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Engineering, Psychology},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/5IFPF2PH/Hohenstein et al. - 2023 - Artificial intelligence in communication impacts language and social relationships.pdf:application/pdf},
}

@article{noy_experimental_2023,
	title = {Experimental evidence on the productivity effects of generative artificial intelligence},
	volume = {381},
	url = {https://www.science.org/doi/10.1126/science.adh2586},
	doi = {10.1126/science.adh2586},
	abstract = {We examined the productivity effects of a generative artificial intelligence ({AI}) technology, the assistive chatbot {ChatGPT}, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to {ChatGPT}. Our results show that {ChatGPT} substantially raised productivity: The average time taken decreased by 40\% and output quality rose by 18\%. Inequality between workers decreased, and concern and excitement about {AI} temporarily rose. Workers exposed to {ChatGPT} during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment.},
	pages = {187--192},
	number = {6654},
	journaltitle = {Science},
	author = {Noy, Shakked and Zhang, Whitney},
	urldate = {2026-01-08},
	date = {2023-07-14},
	note = {Publisher: American Association for the Advancement of Science},
}

@online{salganik_bit_2019,
	title = {Bit by Bit {\textbar} Princeton University Press},
	url = {https://press.princeton.edu/books/paperback/9780691196107/bit-by-bit},
	author = {Salganik, Matthew J.},
	urldate = {2026-01-08},
	date = {2019-06-08},
	langid = {english},
	note = {{ISBN}: 9780691196107},
}

@misc{dellermann_future_2021,
	title = {The future of human-{AI} collaboration: a taxonomy of design knowledge for hybrid intelligence systems},
	url = {http://arxiv.org/abs/2105.03354},
	doi = {10.48550/arXiv.2105.03354},
	shorttitle = {The future of human-{AI} collaboration},
	abstract = {Recent technological advances, especially in the field of machine learning, provide astonishing progress on the road towards artificial general intelligence. However, tasks in current real-world business applications cannot yet be solved by machines alone. We, therefore, identify the need for developing socio-technological ensembles of humans and machines. Such systems possess the ability to accomplish complex goals by combining human and artificial intelligence to collectively achieve superior results and continuously improve by learning from each other. Thus, the need for structured design knowledge for those systems arises. Following a taxonomy development method, this article provides three main contributions: First, we present a structured overview of interdisciplinary research on the role of humans in the machine learning pipeline. Second, we envision hybrid intelligence systems and conceptualize the relevant dimensions for system design for the first time. Finally, we offer useful guidance for system developers during the implementation of such applications.},
	number = {{arXiv}:2105.03354},
	publisher = {{arXiv}},
	author = {Dellermann, Dominik and Calma, Adrian and Lipusch, Nikolaus and Weber, Thorsten and Weigel, Sascha and Ebel, Philipp},
	urldate = {2026-01-08},
	date = {2021-05-07},
	eprinttype = {arxiv},
	eprint = {2105.03354 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/PDPKGELE/Dellermann et al. - 2021 - The future of human-AI collaboration a taxonomy of design knowledge for hybrid intelligence systems.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/S6ZMSF7R/2105.html:text/html},
}

@inproceedings{morrison_social_2021,
	location = {New York, {NY}, {USA}},
	title = {Social Sensemaking with {AI}: Designing an Open-ended {AI} Experience with a Blind Child},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445290},
	doi = {10.1145/3411764.3445290},
	series = {{CHI} '21},
	shorttitle = {Social Sensemaking with {AI}},
	abstract = {{AI} technologies are often used to aid people in performing discrete tasks with well-defined goals (e.g., recognising faces in images). Emerging technologies that provide continuous, real-time information enable more open-ended {AI} experiences. In partnership with a blind child, we explore the challenges and opportunities of designing human-{AI} interaction for a system intended to support social sensemaking. Adopting a research-through-design perspective, we reflect upon working with the uncertain capabilities of {AI} systems in the design of this experience. We contribute: (i) a concrete example of an open-ended {AI} system that enabled a blind child to extend his own capabilities; (ii) an illustration of the delta between imagined and actual use, highlighting how capabilities derive from the human-{AI} interaction and not the {AI} system alone; and (iii) a discussion of design choices to craft an ongoing human-{AI} interaction that addresses the challenge of uncertain outputs of {AI} systems.},
	pages = {1--14},
	booktitle = {Proceedings of the 2021 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Morrison, Cecily and Cutrell, Edward and Grayson, Martin and Thieme, Anja and Taylor, Alex and Roumen, Geert and Longden, Camilla and Tschiatschek, Sebastian and Faia Marques, Rita and Sellen, Abigail},
	urldate = {2026-01-08},
	date = {2021-05-07},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/P5GTAUKC/Morrison et al. - 2021 - Social Sensemaking with AI Designing an Open-ended AI Experience with a Blind Child.pdf:application/pdf},
}

@misc{reddy_shared_2018,
	title = {Shared Autonomy via Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1802.01744},
	doi = {10.48550/arXiv.1802.01744},
	abstract = {In shared autonomy, user input is combined with semi-autonomous control to achieve a common goal. The goal is often unknown ex-ante, so prior work enables agents to infer the goal from user input and assist with the task. Such methods tend to assume some combination of knowledge of the dynamics of the environment, the user's policy given their goal, and the set of possible goals the user might target, which limits their application to real-world scenarios. We propose a deep reinforcement learning framework for model-free shared autonomy that lifts these assumptions. We use human-in-the-loop reinforcement learning with neural network function approximation to learn an end-to-end mapping from environmental observation and user input to agent action values, with task reward as the only form of supervision. This approach poses the challenge of following user commands closely enough to provide the user with real-time action feedback and thereby ensure high-quality user input, but also deviating from the user's actions when they are suboptimal. We balance these two needs by discarding actions whose values fall below some threshold, then selecting the remaining action closest to the user's input. Controlled studies with users (n = 12) and synthetic pilots playing a video game, and a pilot study with users (n = 4) flying a real quadrotor, demonstrate the ability of our algorithm to assist users with real-time control tasks in which the agent cannot directly access the user's private information through observations, but receives a reward signal and user input that both depend on the user's intent. The agent learns to assist the user without access to this private information, implicitly inferring it from the user's input. This paper is a proof of concept that illustrates the potential for deep reinforcement learning to enable flexible and practical assistive systems.},
	number = {{arXiv}:1802.01744},
	publisher = {{arXiv}},
	author = {Reddy, Siddharth and Dragan, Anca D. and Levine, Sergey},
	urldate = {2026-01-08},
	date = {2018-05-23},
	eprinttype = {arxiv},
	eprint = {1802.01744 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Human-Computer Interaction, Computer Science - Robotics},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/L7Q55UNJ/Reddy et al. - 2018 - Shared Autonomy via Deep Reinforcement Learning.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/C7JTAFZ8/1802.html:text/html},
}

@inproceedings{eiband_how_2021,
	location = {New York, {NY}, {USA}},
	title = {How to Support Users in Understanding Intelligent Systems? Structuring the Discussion},
	isbn = {978-1-4503-8017-1},
	url = {https://dl.acm.org/doi/10.1145/3397481.3450694},
	doi = {10.1145/3397481.3450694},
	series = {{IUI} '21},
	shorttitle = {How to Support Users in Understanding Intelligent Systems?},
	abstract = {The opaque nature of many intelligent systems violates established usability principles and thus presents a challenge for human-computer interaction. Research in the field therefore highlights the need for transparency, scrutability, intelligibility, interpretability and explainability, among others. While all of these terms carry a vision of supporting users in understanding intelligent systems, the underlying notions and assumptions about users and their interaction with the system often remain unclear. We review the literature in {HCI} through the lens of implied user questions to synthesise a conceptual framework integrating user mindsets, user involvement, and knowledge outcomes to reveal, differentiate and classify current notions in prior work. This framework aims to resolve conceptual ambiguity in the field and enables researchers to clarify their assumptions and become aware of those made in prior work. We thus hope to advance and structure the dialogue in the {HCI} research community on supporting users in understanding intelligent systems.},
	pages = {120--132},
	booktitle = {Proceedings of the 26th International Conference on Intelligent User Interfaces},
	publisher = {Association for Computing Machinery},
	author = {Eiband, Malin and Buschek, Daniel and Hussmann, Heinrich},
	urldate = {2026-01-08},
	date = {2021-04-14},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/JWLW3QHW/Eiband et al. - 2021 - How to Support Users in Understanding Intelligent Systems Structuring the Discussion.pdf:application/pdf},
}

@article{holzinger_information_2022,
	title = {Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence},
	volume = {79},
	issn = {1566-2535},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253521002050},
	doi = {10.1016/j.inffus.2021.10.007},
	abstract = {Medical artificial intelligence ({AI}) systems have been remarkably successful, even outperforming human performance at certain tasks. There is no doubt that {AI} is important to improve human health in many ways and will disrupt various medical workflows in the future. Using {AI} to solve problems in medicine beyond the lab, in routine environments, we need to do more than to just improve the performance of existing {AI} methods. Robust {AI} solutions must be able to cope with imprecision, missing and incorrect information, and explain both the result and the process of how it was obtained to a medical expert. Using conceptual knowledge as a guiding model of reality can help to develop more robust, explainable, and less biased machine learning models that can ideally learn from less data. Achieving these goals will require an orchestrated effort that combines three complementary Frontier Research Areas: (1) Complex Networks and their Inference, (2) Graph causal models and counterfactuals, and (3) Verification and Explainability methods. The goal of this paper is to describe these three areas from a unified view and to motivate how information fusion in a comprehensive and integrative manner can not only help bring these three areas together, but also have a transformative role by bridging the gap between research and practical applications in the context of future trustworthy medical {AI}. This makes it imperative to include ethical and legal aspects as a cross-cutting discipline, because all future solutions must not only be ethically responsible, but also legally compliant.},
	pages = {263--278},
	journaltitle = {Information Fusion},
	author = {Holzinger, Andreas and Dehmer, Matthias and Emmert-Streib, Frank and Cucchiara, Rita and Augenstein, Isabelle and Ser, Javier Del and Samek, Wojciech and Jurisica, Igor and Díaz-Rodríguez, Natalia},
	urldate = {2026-01-08},
	date = {2022-03-01},
	keywords = {Artificial intelligence, Explainability, Explainable {AI}, Graph-based machine learning, Information fusion, Medical {AI}, Neural-symbolic learning and reasoning, Robustness, Trust},
	file = {ScienceDirect Full Text PDF:/home/mhetac/Zotero/storage/NS3QARHV/Holzinger et al. - 2022 - Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trust.pdf:application/pdf},
}

@inproceedings{yang_re-examining_2020,
	location = {New York, {NY}, {USA}},
	title = {Re-examining Whether, Why, and How Human-{AI} Interaction Is Uniquely Difficult to Design},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376301},
	doi = {10.1145/3313831.3376301},
	series = {{CHI} '20},
	abstract = {Artificial Intelligence ({AI}) plays an increasingly important role in improving {HCI} and user experience. Yet many challenges persist in designing and innovating valuable human-{AI} interactions. For example, {AI} systems can make unpredictable errors, and these errors damage {UX} and even lead to undesired societal impact. However, {HCI} routinely grapples with complex technologies and mitigates their unintended consequences. What makes {AI} different? What makes human-{AI} interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-{AI} interaction. We identify two sources of {AI}'s distinctive design challenges: 1) uncertainty surrounding {AI}'s capabilities, 2) {AI}'s output complexity, spanning from simple to adaptive complex. We identify four levels of {AI} systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-{AI} interaction going forward.},
	pages = {1--13},
	booktitle = {Proceedings of the 2020 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Yang, Qian and Steinfeld, Aaron and Rosé, Carolyn and Zimmerman, John},
	urldate = {2026-01-08},
	date = {2020-04-23},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/T8872KNQ/Yang et al. - 2020 - Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design.pdf:application/pdf},
}

@inproceedings{park_generative_2023,
	location = {New York, {NY}, {USA}},
	title = {Generative Agents: Interactive Simulacra of Human Behavior},
	isbn = {979-8-4007-0132-0},
	url = {https://dl.acm.org/doi/10.1145/3586183.3606763},
	doi = {10.1145/3586183.3606763},
	series = {{UIST} '23},
	shorttitle = {Generative Agents},
	abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
	pages = {1--22},
	booktitle = {Proceedings of the 36th Annual {ACM} Symposium on User Interface Software and Technology},
	publisher = {Association for Computing Machinery},
	author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	urldate = {2026-01-08},
	date = {2023-10-29},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/G26EXQIE/Park et al. - 2023 - Generative Agents Interactive Simulacra of Human Behavior.pdf:application/pdf},
}

@article{ueshima_simple_2024,
	title = {Simple autonomous agents can enhance creative semantic discovery by human groups},
	volume = {15},
	rights = {2024 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-49528-y},
	doi = {10.1038/s41467-024-49528-y},
	abstract = {Innovation is challenging, and theory and experiments indicate that groups may be better able to identify and preserve innovations than individuals. But innovation within groups faces its own challenges, including groupthink and truncated diffusion. We performed experiments involving a game in which people search for ideas in various conditions: alone, in networked social groups, or in networked groups featuring autonomous agents (bots). The objective was to search a semantic space of 20,000 nouns with defined similarities for an arbitrary noun with the highest point value. Participants (N = 1875) were embedded in networks (n = 125) of 15 nodes to which we sometimes added 2 bots. The bots had 3 possible strategies: they shared a random noun generated by their immediate neighbors, or a noun most similar from among those identified, or a noun least similar. We first confirm that groups are better able to explore a semantic space than isolated individuals. Then we show that when bots that share the most similar noun operate in groups facing a semantic space that is relatively easy to navigate, group performance is superior. Simple autonomous agents with interpretable behavior can affect the capacity for creative discovery of human groups.},
	pages = {5212},
	number = {1},
	journaltitle = {Nat Commun},
	author = {Ueshima, Atsushi and Jones, Matthew I. and Christakis, Nicholas A.},
	urldate = {2026-01-08},
	date = {2024-06-18},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Human behaviour, Social sciences},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/Y9HSWI6R/Ueshima et al. - 2024 - Simple autonomous agents can enhance creative semantic discovery by human groups.pdf:application/pdf},
}

@misc{schneider_humans_2020,
	title = {Humans learn too: Better Human-{AI} Interaction using Optimized Human Inputs},
	url = {http://arxiv.org/abs/2009.09266},
	doi = {10.48550/arXiv.2009.09266},
	shorttitle = {Humans learn too},
	abstract = {Humans rely more and more on systems with {AI} components. The {AI} community typically treats human inputs as a given and optimizes {AI} models only. This thinking is one-sided and it neglects the fact that humans can learn, too. In this work, human inputs are optimized for better interaction with an {AI} model while keeping the model fixed. The optimized inputs are accompanied by instructions on how to create them. They allow humans to save time and cut on errors, while keeping required changes to original inputs limited. We propose continuous and discrete optimization methods modifying samples in an iterative fashion. Our quantitative and qualitative evaluation including a human study on different hand-generated inputs shows that the generated proposals lead to lower error rates, require less effort to create and differ only modestly from the original samples.},
	number = {{arXiv}:2009.09266},
	publisher = {{arXiv}},
	author = {Schneider, Johannes},
	urldate = {2026-01-08},
	date = {2020-09-19},
	eprinttype = {arxiv},
	eprint = {2009.09266 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/2PCHBTMB/Schneider - 2020 - Humans learn too Better Human-AI Interaction using Optimized Human Inputs.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/SGUWEEPR/2009.html:text/html},
}

@misc{sclar_quantifying_2024,
	title = {Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting},
	url = {http://arxiv.org/abs/2310.11324},
	doi = {10.48550/arXiv.2310.11324},
	shorttitle = {Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or},
	abstract = {As large language models ({LLMs}) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on {LLM} sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source {LLMs} are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using {LLaMA}-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating {LLMs} with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose {FormatSpread}, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.},
	number = {{arXiv}:2310.11324},
	publisher = {{arXiv}},
	author = {Sclar, Melanie and Choi, Yejin and Tsvetkov, Yulia and Suhr, Alane},
	urldate = {2026-01-08},
	date = {2024-07-01},
	eprinttype = {arxiv},
	eprint = {2310.11324 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/SRKY8HP3/Sclar et al. - 2024 - Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or How I learned to.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/4BT89NIU/2310.html:text/html},
}

@misc{salinas_butterfly_2024,
	title = {The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance},
	url = {http://arxiv.org/abs/2401.03729},
	doi = {10.48550/arXiv.2401.03729},
	shorttitle = {The Butterfly Effect of Altering Prompts},
	abstract = {Large Language Models ({LLMs}) are regularly being used to label data across many domains and for myriad tasks. By simply asking the {LLM} for an answer, or ``prompting,'' practitioners are able to use {LLMs} to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work, we ask: do variations in the way a prompt is constructed change the ultimate decision of the {LLM}? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the {LLM} to change its answer. Further, we find that requesting responses in {XML} and commonly used jailbreaks can have cataclysmic effects on the data labeled by {LLMs}.},
	number = {{arXiv}:2401.03729},
	publisher = {{arXiv}},
	author = {Salinas, Abel and Morstatter, Fred},
	urldate = {2026-01-08},
	date = {2024-04-01},
	eprinttype = {arxiv},
	eprint = {2401.03729 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/CNBDQJNC/Salinas and Morstatter - 2024 - The Butterfly Effect of Altering Prompts How Small Changes and Jailbreaks Affect Large Language Mod.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/ACINBQDM/2401.html:text/html},
}

@misc{cheng_elephant_2025,
	title = {{ELEPHANT}: Measuring and understanding social sycophancy in {LLMs}},
	url = {http://arxiv.org/abs/2505.13995},
	doi = {10.48550/arXiv.2505.13995},
	shorttitle = {{ELEPHANT}},
	abstract = {{LLMs} are known to exhibit sycophancy: agreeing with and flattering users, even at the cost of correctness. Prior work measures sycophancy only as direct agreement with users' explicitly stated beliefs that can be compared to a ground truth. This fails to capture broader forms of sycophancy such as affirming a user's self-image or other implicit beliefs. To address this gap, we introduce social sycophancy, characterizing sycophancy as excessive preservation of a user's face (their desired self-image), and present {ELEPHANT}, a benchmark for measuring social sycophancy in an {LLM}. Applying our benchmark to 11 models, we show that {LLMs} consistently exhibit high rates of social sycophancy: on average, they preserve user's face 45 percentage points more than humans in general advice queries and in queries describing clear user wrongdoing (from Reddit's r/{AmITheAsshole}). Furthermore, when prompted with perspectives from either side of a moral conflict, {LLMs} affirm both sides (depending on whichever side the user adopts) in 48\% of cases--telling both the at-fault party and the wronged party that they are not wrong--rather than adhering to a consistent moral or value judgment. We further show that social sycophancy is rewarded in preference datasets, and that while existing mitigation strategies for sycophancy are limited in effectiveness, model-based steering shows promise for mitigating these behaviors. Our work provides theoretical grounding and an empirical benchmark for understanding and addressing sycophancy in the open-ended contexts that characterize the vast majority of {LLM} use cases.},
	number = {{arXiv}:2505.13995},
	publisher = {{arXiv}},
	author = {Cheng, Myra and Yu, Sunny and Lee, Cinoo and Khadpe, Pranav and Ibrahim, Lujain and Jurafsky, Dan},
	urldate = {2026-01-08},
	date = {2025-09-29},
	eprinttype = {arxiv},
	eprint = {2505.13995 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/PIDZWZXJ/Cheng et al. - 2025 - ELEPHANT Measuring and understanding social sycophancy in LLMs.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/G7DGGKVS/2505.html:text/html},
}

@misc{shum_eliza_2018,
	title = {From Eliza to {XiaoIce}: Challenges and Opportunities with Social Chatbots},
	url = {http://arxiv.org/abs/1801.01957},
	doi = {10.48550/arXiv.1801.01957},
	shorttitle = {From Eliza to {XiaoIce}},
	abstract = {Conversational systems have come a long way since their inception in the 1960s. After decades of research and development, we've seen progress from Eliza and Parry in the 60's and 70's, to task-completion systems as in the {DARPA} Communicator program in the 2000s, to intelligent personal assistants such as Siri in the 2010s, to today's social chatbots like {XiaoIce}. Social chatbots' appeal lies not only in their ability to respond to users' diverse requests, but also in being able to establish an emotional connection with users. The latter is done by satisfying users' need for communication, affection, as well as social belonging. To further the advancement and adoption of social chatbots, their design must focus on user engagement and take both intellectual quotient ({IQ}) and emotional quotient ({EQ}) into account. Users should want to engage with a social chatbot; as such, we define the success metric for social chatbots as conversation-turns per session ({CPS}). Using {XiaoIce} as an illustrative example, we discuss key technologies in building social chatbots from core chat to visual awareness to skills. We also show how {XiaoIce} can dynamically recognize emotion and engage the user throughout long conversations with appropriate interpersonal responses. As we become the first generation of humans ever living with {AI}, we have a responsibility to design social chatbots to be both useful and empathetic, so they will become ubiquitous and help society as a whole.},
	number = {{arXiv}:1801.01957},
	publisher = {{arXiv}},
	author = {Shum, Heung-Yeung and He, Xiaodong and Li, Di},
	urldate = {2026-01-08},
	date = {2018-02-09},
	eprinttype = {arxiv},
	eprint = {1801.01957 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	file = {Preprint PDF:/home/mhetac/Zotero/storage/BBJGVFBD/Shum et al. - 2018 - From Eliza to XiaoIce Challenges and Opportunities with Social Chatbots.pdf:application/pdf;Snapshot:/home/mhetac/Zotero/storage/EKIEG9J9/1801.html:text/html},
}

@inproceedings{chen_how_2019,
	location = {New York, {NY}, {USA}},
	title = {How Serendipity Improves User Satisfaction with Recommendations? A Large-Scale User Evaluation},
	isbn = {978-1-4503-6674-8},
	url = {https://dl.acm.org/doi/10.1145/3308558.3313469},
	doi = {10.1145/3308558.3313469},
	series = {{WWW} '19},
	shorttitle = {How Serendipity Improves User Satisfaction with Recommendations?},
	abstract = {Recommendation serendipity is being increasingly recognized as being equally important as the other beyond-accuracy objectives (such as novelty and diversity), in eliminating the “filter bubble” phenomenon of the traditional recommender systems. However, little work has empirically verified the effects of serendipity on increasing user satisfaction and behavioral intention. In this paper, we report the results of a large-scale user survey (involving over 3,000 users) conducted in an industrial mobile e-commerce setting. The study has identified the significant causal relationships from novelty, unexpectedness, relevance, and timeliness to serendipity, and from serendipity to user satisfaction and purchase intention. Moreover, our findings reveal that user curiosity plays a moderating role in strengthening the relationships from novelty to serendipity and from serendipity to satisfaction. Our third contribution lies in the comparison of several recommender algorithms, which demonstrates the significant improvements of the serendipity-oriented algorithm over the relevance- and novelty-oriented approaches in terms of user perceptions. We finally discuss the implications of this experiment, which include the feasibility of developing a more precise metric for measuring recommendation serendipity, and the potential benefit of a curiosity-based personalized serendipity strategy for recommender systems.},
	pages = {240--250},
	booktitle = {The World Wide Web Conference},
	publisher = {Association for Computing Machinery},
	author = {Chen, Li and Yang, Yonghua and Wang, Ningxia and Yang, Keping and Yuan, Quan},
	urldate = {2026-01-08},
	date = {2019-05-13},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/STTUPHCT/Chen et al. - 2019 - How Serendipity Improves User Satisfaction with Recommendations A Large-Scale User Evaluation.pdf:application/pdf},
}

@inproceedings{radford_improving_2018,
	title = {Improving Language Understanding by Generative Pre-Training},
	url = {https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering ({RACE}), and 1.5\% on textual entailment ({MultiNLI}).},
	author = {Radford, Alec and Narasimhan, Karthik},
	urldate = {2026-01-08},
	date = {2018},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/7RIG3W52/Radford and Narasimhan - 2018 - Improving Language Understanding by Generative Pre-Training.pdf:application/pdf},
}

@online{mollman_artificial_2022,
	title = {Artificial intelligence chatbot {ChatGPT} has gained 1 million followers in a single week. Here's why it's primed to disrupt search as we know it},
	url = {https://fortune.com/2022/12/09/ai-chatbot-chatgpt-could-disrupt-google-search-engines-business/},
	abstract = {Google could face disruption from {ChatGPT}, a new A.I. chatbot that provides straightforward, uncluttered answers to questions.},
	titleaddon = {Fortune},
	author = {Mollman, Steve},
	urldate = {2026-01-08},
	date = {2022-12-09},
	langid = {english},
	file = {Snapshot:/home/mhetac/Zotero/storage/T6QGYPIE/ai-chatbot-chatgpt-could-disrupt-google-search-engines-business.html:text/html},
}

@article{wang_era_2020,
	title = {The Era of Intelligent Recommendation: Editorial on Intelligent Recommendation with Advanced {AI} and Learning},
	volume = {35},
	issn = {1941-1294},
	url = {https://ieeexplore.ieee.org/document/9237281},
	doi = {10.1109/MIS.2020.3026430},
	shorttitle = {The Era of Intelligent Recommendation},
	abstract = {The articles in this special section address intelligent recommender systems using advanced artificial intelligence ({AI}) learning applications.},
	pages = {3--6},
	number = {5},
	journaltitle = {{IEEE} Intelligent Systems},
	author = {Wang, Shoujin and Pasi, Gabriella and Hu, Liang and Cao, Longbing},
	urldate = {2026-01-08},
	date = {2020-09},
	keywords = {Artificial intelligence, Intelligent systems, Machine learning, Recommender systems, Special issues and sections},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/FIDR56KP/Wang et al. - 2020 - The Era of Intelligent Recommendation Editorial on Intelligent Recommendation with Advanced AI and.pdf:application/pdf},
}

@incollection{holzinger_explainable_2022,
	location = {Cham},
	title = {Explainable {AI} Methods - A Brief Overview},
	isbn = {978-3-031-04083-2},
	url = {https://doi.org/10.1007/978-3-031-04083-2_2},
	abstract = {Explainable Artificial Intelligence ({xAI}) is an established field with a vibrant community that has developed a variety of very successful approaches to explain and interpret predictions of complex machine learning models such as deep neural networks. In this article, we briefly introduce a few selected methods and discuss them in a short, clear and concise way. The goal of this article is to give beginners, especially application engineers and data scientists, a quick overview of the state of the art in this current topic. The following 17 methods are covered in this chapter: {LIME}, Anchors, {GraphLIME}, {LRP}, {DTD}, {PDA}, {TCAV}, {XGNN}, {SHAP}, {ASV}, Break-Down, Shapley Flow, Textual Explanations of Visual Models, Integrated Gradients, Causal Models, Meaningful Perturbations, and X-{NeSyL}.},
	pages = {13--38},
	booktitle = {{xxAI} - Beyond Explainable {AI}: International Workshop, Held in Conjunction with {ICML} 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers},
	publisher = {Springer International Publishing},
	author = {Holzinger, Andreas and Saranti, Anna and Molnar, Christoph and Biecek, Przemyslaw and Samek, Wojciech},
	editor = {Holzinger, Andreas and Goebel, Randy and Fong, Ruth and Moon, Taesup and Müller, Klaus-Robert and Samek, Wojciech},
	urldate = {2026-01-08},
	date = {2022},
	langid = {english},
	doi = {10.1007/978-3-031-04083-2_2},
	keywords = {Evaluation, Explainable {AI}, Methods},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/HX4YGY64/Holzinger et al. - 2022 - Explainable AI Methods - A Brief Overview.pdf:application/pdf},
}

@article{turing_computing_1950,
	title = {Computing Machinery and Intelligence},
	volume = {49},
	url = {https://www.csee.umbc.edu/courses/471/papers/turing.pdf},
	pages = {433--460},
	journaltitle = {Computing Machinery and Intelligence. Mind},
	author = {Turing, Alan},
	date = {1950},
}

@article{holzinger_toward_2021,
	title = {Toward Human–{AI} Interfaces to Support Explainability and Causability in Medical {AI}},
	volume = {54},
	issn = {1558-0814},
	url = {https://ieeexplore.ieee.org/document/9548137},
	doi = {10.1109/MC.2021.3092610},
	abstract = {Our concept of causability is a measure of whether and to what extent humans can understand a given machine explanation. We motivate causability with a clinical case from cancer research. We argue for using causability in medical artificial intelligence ({AI}) to develop and evaluate future human–{AI} interfaces.},
	pages = {78--86},
	number = {10},
	journaltitle = {Computer},
	author = {Holzinger, Andreas and Müller, Heimo},
	urldate = {2026-01-08},
	date = {2021-10},
	keywords = {Artificial intelligence, Cancer},
	file = {Full Text PDF:/home/mhetac/Zotero/storage/ELSQ243T/Holzinger and Müller - 2021 - Toward Human–AI Interfaces to Support Explainability and Causability in Medical AI.pdf:application/pdf},
}

@online{rosario_generative_1,
	title = {Generative {AI} and Generative Pre-Trained Transformer Applications: Challenges and Opportunities},
	rights = {Access limited to members},
	url = {https://www.igi-global.com/gateway/chapter/www.igi-global.com/gateway/chapter/343418},
	shorttitle = {Generative {AI} and Generative Pre-Trained Transformer Applications},
	abstract = {Generative {AI}, such as generative pre-trained transformer ({GPT}), has seen rapid advancements in recent years, offering a wide range of applications, but it also presents several challenges and opportunities. {GPT} can automate content generation for various industries, including journalism, marketing,...},
	titleaddon = {https://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/979-8-3693-1950-5.ch003},
	type = {chapter},
	author = {Rosário, Albérico Travassos and Rosário, Albérico Travassos},
	urldate = {2026-01-08},
	date = {0001-01-01},
	doi = {10.4018/979-8-3693-1950-5.ch003},
	note = {Archive Location: generative-ai-and-generative-pre-trained-transformer-applications
{ISBN}: 9798369319505
Publisher: {IGI} Global Scientific Publishing},
	file = {Snapshot:/home/mhetac/Zotero/storage/YRHMNZXF/343418.html:text/html},
}

@online{CCC_artificial_2016,
	title = {Artificial Intelligence For Social Good - {CCC}},
	url = {https://cra.org/ccc/events/ai-social-good/},
	abstract = {There has been a dramatically increasing interest in Artificial Intelligence ({AI}) in recent years. {AI} has been successfully applied to societal challenge problems and it has a great potential to provide tremendous social good in the future. In this workshop, we discussed the successful deployments and the potential use of {AI} in various topics that are essential for social good, including but not limited to urban computing, health, environmental sustainability and social welfare/disadvantaged segments of society.},
	urldate = {2026-01-08},
	date = {2016-07-06},
	langid = {american},
	file = {Snapshot:/home/mhetac/Zotero/storage/7NTV6ZIR/ai-social-good.html:text/html},
}